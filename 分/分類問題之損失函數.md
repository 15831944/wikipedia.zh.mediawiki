{{merge|分类问题|discuss=Talk:分類問題之損失函數#请求与分类问题合并|time=2018-07-05T17:33:46+00:00}}
{{unreferenced|time=2018-07-05T17:33:46+00:00}}
[[File:Loss_function_surrogates.svg|thumb]]

在[[機器學習|機器學習]]和[[最佳化|最佳化]]領域中，分類問題之損失函數可以用來表達預測不準確之程度，其中分類問題主要是用來判斷所偵測到的物件屬於什麼類別。將一個向量空間<math>X</math>做為所有的輸入值，而向量空間<math>Y=\{-1, 1\}</math>做為所有的輸出值。我们希望能夠找到最佳的公式<math>f: X\rightarrow\Re</math>將<math>\vec{x}</math>映射到<math>y</math><ref name="penn">{{Citation | last= Shen | first= Yi | title= Loss Functions For Binary Classification and Class Probability Estimation | publisher= University of Pennsylvania | year= 2005 | url= http://stat.wharton.upenn.edu/~buja/PAPERS/yi-shen-dissertation.pdf | accessdate= 6 December 2014}}</ref>。然而，由于信息不完整、雜訊、计算過程中的非确定性模块等因素，有可能會有相同的輸入值<math>\vec{x}</math>映射到不同的輸出值<math>y</math><ref name="mitlec">{{Citation | last= Rosasco | first= Lorenzo | last2= Poggio | first2= Tomaso | title= A Regularization Tour of Machine Learning | series= MIT-9.520 Lectures Notes | volume= Manuscript | year= 2014}}</ref>。因此，這個學習過程的目的就是要最小化預期風險（更详细的介绍参见[[统计学习理论|统计学习理论]]），預期風險之定義為：

:<math>I[f]=\textstyle \int_{X \times Y}^{} \displaystyle V(f(\vec{x},y))p(\vec{x},y)d\vec{x}dy</math>

其中<math>V(f(\vec{x},y))</math>即損失函數，而<math>p(\vec{x},y)</math>為機率密度函數。而實作上概率分布<math>p(\vec{x},y)</math>通常是未知的，因此我们使用由数据[[样本空间|样本空间]]中取出的<math>n</math>個[[独立同分布|獨立且同分布]]（i.i.d.）的樣本點
:<math>S=\{(\vec{x_1},y_1),...,(\vec{x_n},y_n)\}</math>作为训练集，將樣本空間所得到的经验風險做為預期風險的替代，其定義為：

:<math>I_S[f]=\frac{1}{n}\sum_{i=1}^n V(f(\vec{x_i},y_i))</math>

基於分類問題的二元性，可定義0-1函數做為匹配值之基準。因此損失函數為：

:<math>V(f(\vec{x},y))=H(-yf(\vec{x}))</math>

其中<math>H</math>為[[单位阶跃函数|步階函數]]。然而損失函數並不是[[凸函数|凸函數]]或平滑函數，是一種[[NP困难|NP-hard]]的問題，因此做為替代，需要使用可以追蹤的機器學習演算法（透過凸損失函數）。

== 分類問題之界線 ==
使用貝式定理，可以基於問題的二元性最佳化映射公式<math>f^*</math>為：

:<math>f^*(\vec{x}) = \begin{cases} 
1, & \text{if }p(1\mid\vec{x})>p(-1\mid\vec{x}) \\ 
-1, & \text{if }p(1\mid\vec{x})<p(-1\mid\vec{x}) 
\end{cases}</math>

當<math>p(1\mid\vec{x})\neq p(-1\mid\vec{x})</math>

== 簡化分類問題預期風險 ==
:<math>\begin{alignat}{4} 
I[f(x)] & = \int_{X\times Y}^{} V(f(\vec{x},y))p(\vec{x},y)d\vec{x}dy \\ 
& = \int_{X}^{}\int_{Y}^{} V(f(\vec{x},y))p(\vec{x},y)p(\vec{x})dyd\vec{x} \\ 
& = \int_{X}^{} [V(-f(\vec{x})p(1\mid x)+V(f(\vec{x})p(-1\mid x)]p(\vec{x})d\vec{x} \\
& = \int_{X}^{} [V(-f(\vec{x})p(1\mid x)+V(f(\vec{x})(1-p(1\mid x))]p(\vec{x})d\vec{x}
\end{alignat}</math>

== 平方損失 ==
:<math>V(f(\vec{x},y))=(1-yf(\vec{x}))^2</math>

平方損失凸且平滑，但容易過度懲罰錯誤預測，導致收斂速度比邏輯損失和鏈結損失慢。它的優點為有助於簡化[[交叉驗證|交叉驗證]]之正則化（[[regularization|regularization]]）。

最小化預期風險之映射函數為：

:<math>f^*_{Square}=2p(1\mid x)-1</math>

== 鏈結損失 ==
:<math>V(f(\vec{x}),y) = \max(0, 1-yf(\vec{x})) = |1 - yf(\vec{x}) |_{+}</math>
鏈結損失公式等同於[[支持向量機|支持向量機]]（SVM）的損失公式。鏈結損失凸但不平滑（在<math>yf(\vec{x})) = 1</math>不可微分），因此不適用於[[梯度下降法|梯度下降法]]和[[隨機梯度下降法|隨機梯度下降法]]，但適用[[次梯度下降法|次梯度下降法]]。
最小化預期風險之映射函數為：
:<math>f^*_{Square}=2p(1\mid x)-1</math>

== 廣義平滑鏈結損失 ==
:<math>f^*_\alpha(z) \;=\; \begin{cases} \frac{\alpha}{\alpha + 1}& \text{if }z< 0 \\ \frac{1}{\alpha + 1}z^{\alpha + 1} - z + \frac{\alpha}{\alpha + 1} & \text{if } 0<z<1 \\ 0 & \text{if } z \geq 1 \end{cases}</math>
其中<math>z = yf(\vec{x})</math>

== 邏輯損失 ==
:<math>V(f(\vec{x}),y) = \frac{1}{\ln 2}\ln(1+e^{-yf(\vec{x})})</math>
適用於梯度下降法，但不會對錯誤預測做懲罰。
最小化預期風險之映射函數為：
:<math>f^*_\text{Logistic}= \ln\left(\frac{p(1\mid x)}{1-p(1\mid x)}\right).</math>

== 交叉熵損失 ==
:<math>V(f(\vec{x}),t) = -t\ln(f(\vec{x}))-(1-t)\ln(1-f(\vec{x}))</math>
其中<math>t=(1+y)/2</math> so that <math>t \in \{0,1\}</math>
屬於凸函數，適用於隨機梯度下降法。

== 指數損失 ==
:<math>V(f(\vec{x}),y) = e^{-\beta yf(\vec{x})}</math>