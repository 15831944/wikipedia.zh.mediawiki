{{noteTA
|G1 = IT
|T = zh-cn:大数据; zh-tw:巨量資料;
|1 = zh-cn:大数据; zh-tw:巨量資料;
|2 = zh-cn:数据; zh-tw:資料;

}}
{{original research|time=2014-08-08T15:15:28+00:00}}
-{zh-hans:'''大数据'''; zh-hant:'''巨量資料''';}-（{{lang-en|'''Big data'''}}<ref>{{cite book |first=Tom |last=White |title=Hadoop: The Definitive Guide |url=http://books.google.com/books?id=Wu_xeGdU4G8C&pg=PA3 |date=2012-05-10 |publisher=O'Reilly Media |isbn=978-1-4493-3877-0 |page=3}}</ref><ref>{{cite web |title=MIKE2.0, Big Data Definition |url=http://mike2.openmethodology.org/wiki/Big_Data_Definition}}</ref><ref>{{cite web |title=巨量資料與進階分析解決方案 | Microsoft Azure |url=https://azure.microsoft.com/zh-tw/solutions/big-data/}}</ref>）-{zh-hans:，又称为'''巨量资料'''; zh-hant:，又稱為'''大數據''';}-，指的是傳統數據處理應用軟件不足以處理它們的大或複雜的數據集的術語<ref>{{cite web|author=Kusnetzky, Dan |title=What is "Big Data?" |publisher=ZDNet |url=http://blogs.zdnet.com/virtualization/?p=1708 |deadurl=yes |archiveurl=https://web.archive.org/web/20100221024502/http://blogs.zdnet.com/virtualization/?p=1708 |archivedate=2010-02-21 }}</ref><ref>{{cite web |author=Vance, Ashley |title=Start-Up Goes After Big Data With Hadoop Helper |date=2010-04-22 |work=New York Times Blog |url=http://bits.blogs.nytimes.com/2010/04/22/start-up-goes-after-big-data-with-hadoop-helper/?dbk}}</ref>。大數據也可以定義為來自各種來源的大量非結構化或結構化數據。從學術角度而言，大數據的出現促成了廣泛主題的新穎研究。這也導致了各種大數據統計方法的發展。大數據並沒有[[抽樣|抽樣]]；它只是觀察和追踪發生的事情。因此，大數據通常包含的數據大小超出了傳統軟件在可接受的時間內處理的能力。由於近期的技術進步，發布新數據的便捷性以及全球大多數政府對高透明度的要求，大數據分析在現代研究中越來越突出。<ref>{{cite article |first=Rita Yi Man |last=Li |title=Have Housing Prices Gone with the Smelly Wind? Big Data Analysis on Landfill in Hong Kong, Sustainability 2018, 10(2), 341; doi:10.3390/su10020341 |url=http://www.mdpi.com/2071-1050/10/2/341/htm |publisher=MDPI}}</ref> <ref>{{cite web |title=MIKE2.0, Big Data Definition |url=http://mike2.openmethodology.org/wiki/Big_Data_Definition}}</ref>

== 概述 ==
{{As of|2012|}}，技術上可在合理時間內分析處理的資料集大小單位為[[位元|艾位元組]]（{{lang|en|EB}}）<ref name="Ars%252520Technica">{{cite web|url=http://arstechnica.com/science/2012/04/future-telescope-array-drives-development-of-exabyte-processing/|title=Future telescope array drives development of exabyte processing|date=2012-04-02|accessdate=2012-10-24|author=Francis, Matthew}}</ref>。在許多領域，由於資料集過度龐大，科學家經常在分析處理上遭遇限制和阻礙；這些領域包括[[氣象學|氣象學]]、[[基因組學|基因組學]]<ref>{{cite journal |title=Community cleverness required |journal=Nature |volume=455 |issue=7209 |page=1 |date=4 September 2008 |doi=10.1038/455001a |url=http://www.nature.com/nature/journal/v455/n7209/full/455001a.html}}</ref>、[[神經網路體學|神經網路體學]]、複雜的物理模擬<ref>{{cite web|title=Sandia sees data management challenges spiral |date=2009-08-04 |work=HPC Projects |url=http://www.hpcprojects.com/news/news_story.php?news_id=922 |deadurl=yes |archiveurl=https://web.archive.org/web/20110511011635/http://www.hpcprojects.com/news/news_story.php?news_id=922 |archivedate=2011-05-11 }}</ref>，以及生物和環境研究<ref>{{cite journal |last1=Reichman |first1=O.J. |last2=Jones |first2=M.B. |last3=Schildhauer |first3=M.P. |title=Challenges and Opportunities of Open Data in Ecology |journal=Science |volume=331 |issue=6018 |pages=703–5 |year=2011 |doi=10.1126/science.1197962 }}</ref>。這樣的限制也對[[搜索引擎|网络搜索]]、[[金融|金融]]與[[经济信息学|經濟資訊學]]造成影響。資料集大小增長的部分原因來自於資訊持續從各種來源被廣泛收集，這些來源包括搭載感測設備的行動裝置、高空感測科技（[[遥感|遥感]]）、軟體記錄、相機、麥克風、[[無線射頻辨識|無線射頻辨識]]（RFID）和[[無線感測網路|無線感測網路]]。自1980年代起，現代科技可儲存資料的容量每40個月即增加一倍<ref name="HilbertLopez2011">{{harvnb|Hilbert|López|2011}}</ref>；{{As of|2012}}，全世界每天產生2.5[[艾位元組|艾位元組]]（2.5×10<sup>18</sup>字节）的資料<ref>{{cite web|url=http://www.ibm.com/big-data/us/en/ |title=IBM What is big data? — Bringing big data to the enterprise |publisher=www.ibm.com |date= |accessdate=2013-08-26}}</ref>。

巨量資料幾乎無法使用大多數的資料庫管理系統處理，而必須使用「在數十、數百甚至數千台伺服器上同時平行運行的軟體」（[[计算机集群|计算机集群]]是其中一種常用方式）<ref>{{cite web |author=Jacobs, A. |title=The Pathologies of Big Data |date=6 July 2009 |work=ACMQueue |url=http://queue.acm.org/detail.cfm?id=1563874}}</ref>。巨量資料的定義取決於持有資料組的機構之能力，以及其平常用來處理分析資料的軟體之能力。「對某些組織來說，第一次面對數百GB的資料集可能讓他們需要重新思考資料管理的選項。對於其他組織來說，資料集可能需要達到數十或數百[[太字节|TB]]才會對他們造成困擾。」<ref>{{cite journal |last1=Magoulas |first1=Roger |last2=Lorica |first2=Ben |title=Introduction to Big Data |journal=Release 2.0 |issue=11 |date=2009-02 |url=http://radar.oreilly.com/r2/release2-0-11.html |publisher=O'Reilly Media |location=Sebastopol CA}}</ref>

随着大數據被越来越多的提及，有些人惊呼大數據时代已经到来了，2012年《[[纽约时报|纽约时报]]》的一篇专栏中写到，“大數據”时代已经降临，在商业、经济及其他领域中，决策将日益基于數據和分析而作出，而并非基于经验和直觉。但是并不是所有人都对大數據感兴趣，有些人甚至认为这是商学院或咨询公司用来哗众取宠的buzzword，看起来很新颖，但只是把传统重新包装，之前在学术研究或者政策决策中也有海量数据的支撑，大数据并不是一件新兴事物。

大数据时代的来临带来无数的机遇，但是与此同时个人或机构的[[隐私权|隐私权]]也极有可能受到冲击，大數據包含各种个人信息数据，现有的隐私保护法律或政策无力解决这些新出现的问题。有人提出，大数据时代，个人是否拥有“[[被遺忘權|被遗忘权]]”，被遗忘权即是否有权利要求数据商不保留自己的某些信息，大数据时代信息为某些互联网巨头所控制，但是数据商收集任何数据未必都获得用户的许可，其对数据的控制权不具有合法性。2014年5月13日[[歐盟法院|欧盟法院]]就“被遗忘权”（right to be forgotten）一案作出裁定，判决[[Google|谷歌]]应根据用户请求删除不完整的、无关紧要的、不相关的数据以保证数据不出现在搜索结果中。这说明在大数据时代，加强对用户个人权利的尊重才是时勢所趋的潮流。
[[File:Viegas-UserActivityonWikipedia.gif|thumb]]的文字和圖片正是大資料的例子之一]]

[[File:Hilbert_InfoGrowth.png|thumb]]

== 定義 ==
巨量資料由巨型{{Link-en|數據集|Data set}}組成，這些數據集大小常超出人類在可接受時間下的{{Link-en|數據收集|data acquisition|收集}}、{{Link-en|資料庋用|data curation|庋用}}、管理和處理能力<ref name="Editorial">Snijders, C., Matzat, U., & Reips, U.-D. (2012). <nowiki>‘Big Data’: Big gaps of knowledge in the field of Internet science</nowiki>. ''International Journal of Internet Science, 7'', 1-5. http://www.ijis.net/ijis7_1/ijis7_1_editorial.html</ref>。巨量資料的大小經常改變，{{As of|2012}}，單一資料集的大小從數[[太字节|太字节]]（TB）至數十[[拍字节|兆億位元組]]（PB）不等。

在一份2001年的研究與相關的演講中<ref>{{cite web |first=Laney |last=Douglas |title=3D Data Management: Controlling Data Volume, Velocity and Variety |url=http://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf |publisher=Gartner |accessdate = 2001-02-06}}</ref>，[[麦塔集团|麦塔集团]]（META Group，現為[[高德纳咨询公司|高德纳]]）分析員道格·萊尼（{{lang|en|Doug Laney}}）指出數據長的挑戰和機遇有三個方向：量（{{lang|en|Volume}}，數據大小）、速（{{lang|en|Velocity}}，資料输入輸出的速度）與多變（{{lang|en|Variety}}，多样性），合稱「3V」或「3Vs」。高德纳與現在大部份巨量資料產業中的公司，都繼續使用3V來描述大數據<ref>{{cite web|last=Beyer |first=Mark |title=Gartner Says Solving 'Big Data' Challenge Involves More Than Just Managing Volumes of Data |url=http://www.gartner.com/it/page.jsp?id=1731916 |publisher=Gartner |accessdate=2011-07-13 |archiveurl=https://web.archive.org/web/20110710043533/http://www.gartner.com/it/page.jsp?id=1731916 |archivedate=2011-07-10 |deadurl=no }}</ref>。高德納於2012年修改對大數據的定義：「巨量資料是大量、高速、及/或多變的資訊資產，它需要新型的處理方式去促成更強的決策能力、洞察力與最佳化處理<ref group="原文">原文：Big data are high volume, high velocity, and/or high variety information assets that require new forms of processing to enable enhanced decision making, insight discovery and process optimization.</ref><ref>{{cite web |first=Laney |last=Douglas |title=The Importance of 'Big Data': A Definition |url=http://www.gartner.com/resId=2057415 |publisher=Gartner |accessdate=21 June 2012 }}{{Dead link|date=2018年11月 |bot=InternetArchiveBot |fix-attempted=yes }}</ref>。」另外，有機構在3V之外定義第4個V：真实性（{{lang|en|Veracity}}）為第四特点<ref>{{cite web|title=What is Big Data?|url=http://www.villanovau.com/university-online-programs/what-is-big-data/ |publisher=[[Villanova_University|Villanova University]]}}</ref>。

巨量資料必須藉由計算機對資料進行統計、比對、解析方能得出客觀結果。美國在2012年就開始著手大數據，歐巴馬更在同年投入2億美金在大數據的開發中，更強調巨量資料會是之後的未來石油。

[[資料探勘|資料探勘]]（data mining）則是在探討用以解析巨量資料的方法。

大数据需要特殊的技术，以有效地处理大量的容忍经过时间内的数据。适用于大数据的技术，包括大规模并行处理（MPP）数据库、数据挖掘、分布式文件系统、分布式数据库、云计算平台、互联网和可扩展的存储系统。

== 應用範例 ==
巨量資料的應用範例包括[[大科学|大科学]]、[[無線射頻辨識|RFID]]、感測設備網路、[[天文學|天文學]]、大氣學、[[交通運輸|交通運輸]]、基因組學、[[生物学|生物學]]、大社會資料分析<ref name="Cambria13">
{{cite book
 | author = Erik Cambria
 | coauthors = Dheeraj Rajagopal, Daniel Olsher, and Dipankar Das
 | title = Big social data analysis
 | booktitle = Big Data Computing
 | chapter = 13
 | year = 2013
 | publisher = Taylor & Francis
 | url =http://tmrfindia.org/bigdata.html
}}
</ref>、網際網路文件處理、製作網際網路搜尋引擎索引、通信記錄明細、軍事偵查、金融大数据，医疗大数据，社群網路、通勤時間預測、醫療記錄、照片圖像和影像封存、大規模的[[電子商務|電子商務]]等<ref>{{cite web |author=Hogan, M. |title=What is Big Data |date=2013-06-20 |url=http://www.scaledb.com/big-data.php |accessdate=2018-02-18 |deadurl=yes |archiveurl=https://web.archive.org/web/20170722101434/http://www.scaledb.com/big-data-php.php |archivedate=2017-07-22 }}</ref>。
[[File:Ben_Taylor_San_Jose_Giants_Using_Gameday.jpg|缩略图]]
=== 巨大科學 ===
[[大型強子對撞機|大型強子對撞機]]中有1億5000萬個感測器，每秒傳送4000萬次的資料。實驗中每秒產生將近6億次的對撞，在過濾去除99.999%的撞擊資料後，得到約100次的有用撞擊資料<ref>{{cite web |title=LHC Brochure, English version. A presentation of the largest and the most powerful particle accelerator in the world, the Large Hadron Collider (LHC), which started up in 2008. Its role, characteristics, technologies, etc. are explained for the general public. |url=http://cds.cern.ch/record/1278169?ln=en |work=CERN-Brochure-2010-006-Eng. LHC Brochure, English version. |publisher=CERN |accessdate=20 January 2013}}</ref><ref>{{cite web |title=LHC Guide, English version. A collection of facts and figures about the Large Hadron Collider (LHC) in the form of questions and answers. |url=http://cds.cern.ch/record/1092437?ln=en |work=CERN-Brochure-2008-001-Eng. LHC Guide, English version. |publisher=CERN |accessdate=20 January 2013}}</ref><ref name="nature">{{Cite news |title=High-energy physics: Down the petabyte highway |work= Nature |date= 19 January 2011 |first=Geoff |last=Brumfiel |doi= 10.1038/469282a |volume= 469 |pages= 282–83 |url=http://www.nature.com/news/2011/110119/full/469282a.html }}</ref>。

將撞擊結果資料過濾處理後僅記錄0.001%的有用資料，全部四個對撞機的資料量複製前每年產生25[[拍位元組|拍位元組]]（PB），複製後為200拍位元組。

如果將所有實驗中的資料在不過濾的情況下全部記錄，資料量將會變得過度龐大且極難處理。每年資料量在複製前將會達到1.5億拍位元組，等於每天有近500[[艾位元組|艾位元組]]（EB）的資料量。這個數字代表每天實驗將產生相當於500[[垓|垓]]（5×10<sup>20</sup>）位元組的資料，是全世界所有資料來源總和的200倍。

=== 科學研究 ===
=== 衛生學 ===
國際衛生學教授[[漢斯·羅斯林|漢斯·羅斯林]]使用「Trendalyzer」工具軟體呈現兩百多年以來全球人類的人口統計資料，跟其他數據交叉比對，例如收入、宗教、能源使用量等。

=== 公共部门 ===
目前，发达国家的政府部门开始推广大数据的应用。2012年奥巴马政府投资近两亿美元开始推行《大数据的研究与发展计划》，本计划涉及[[美国国防部|美国国防部]]、[[美国卫生及公共服务部|美国卫生与公共服务部门]]等多个联邦部门和机构，意在通过提高从大型复杂的的数据中提取知识的能力，进而加快科学和工程的开发，保障国家安全。
==== 信息审查 ====
{{see also|社会信用体系}}
中国政府计划建立全面的个人信用评分体系，其包含不少对个人行为的评定，有关指标会影响到个人[[贷款|贷款]]、[[工作|工作]]、[[签证|签证]]等生活活动。高科技公司在被政治介入为其目的服务，个人部分行为和社交关系受掌控，几乎无人可免于被纳入个人信用评价体系<ref>{{cite web |author=陈迎竹|title=慎防大数据助长独裁 |date=2017-10-15 |url=http://www.zaobao.com.sg/zopinions/opinions/story20171015-803061 |accessdate=}}</ref>。除獲取網絡數據外，中國政府還希望從科技公司獲得分類和分析信息的[[雲端計算|雲端計算]]能力，透過城市监控摄像机、[[智能手机|智能手機]]、政府[[數據庫|數據庫]]等蒐集數據，以建造[[智慧城市|智慧城市]]和安全城市。[[人權觀察|人權觀察]]駐香港研究員王松蓮指出，整個安全城市構想無非是一個龐大的[[大规模监控|監視項目]]<ref>{{Cite web|url=https://www.thestandnews.com/china/%E8%8F%AF%E7%88%BE%E8%A1%97%E6%97%A5%E5%A0%B1-%E9%98%BF%E9%87%8C-%E9%A8%B0%E8%A8%8A%E6%88%90%E7%82%BA%E6%94%BF%E5%BA%9C%E7%9B%A3%E8%A6%96%E5%9C%8B%E6%B0%91%E7%9A%84%E8%80%B3%E7%9B%AE/|title=華爾街日報：阿里、騰訊成為政府監視國民的耳目|accessdate=|author=|date=2017-12-01|publisher=立場新聞}}</ref>。

=== 民間部門 ===
* [[亚马逊公司|亚马逊公司]]，在2005年的時點，這間公司是世界上最大的以LINUX為基礎的三大資料庫之一<ref>{{cite web|last=Layton |first=Julia |url=http://money.howstuffworks.com/amazon1.htm |title=Amazon Technology |publisher=Money.howstuffworks.com |date= |accessdate=2013-03-05}}</ref>。
* [[沃尔玛|沃尔玛]]可以在1小時內處理百万以上顧客的消費處理。相當於[[美國議會圖書館|美國議會圖書館]]所藏的書籍之167倍的情報量{{r|Economist}}。
* [[Facebook|Facebook]]，處理500億枚的使用者相片<ref>{{cite web|url=https://www.facebook.com/notes/facebook-engineering/scaling-facebook-to-500-million-users-and-beyond/409881258919 |title=Scaling Facebook to 500 Million Users and Beyond |publisher=Facebook.com |date= |accessdate=2013-07-21}}</ref>。
* 全世界商業資料的數量，統計全部的企業全体、推計每1.2年會倍増<ref name="KnowWPCarey.com">{{cite web|url=http://knowwpcarey.com/article.cfm?cid=25&aid=1171 |title=eBay Study: How to Build Trust and Improve the Shopping Experience |publisher=Knowwpcarey.com |date=2012-05-08 |accessdate=2013-03-05 |deadurl=yes |archiveurl=https://web.archive.org/web/20120619040218/http://knowwpcarey.com/article.cfm?cid=25&aid=1171 |archivedate=2012-06-19 }}</ref>。
* [[西雅圖|西雅圖]]{{link-en|文德米爾不動產|Windermere Real Estate}}分析約1億匿名GPS信號，提供購入新房子的客戶從該地點使用交通工具(汽車、腳踏車等)至公司等地的通勤時間估計值<ref>{{cite web|last=Wingfield |first=Nick |url=http://bits.blogs.nytimes.com/2013/03/12/predicting-commutes-more-accurately-for-would-be-home-buyers/ |title=Predicting Commutes More Accurately for Would-Be Home Buyers - NYTimes.com |publisher=Bits.blogs.nytimes.com |date=2013-03-12 |accessdate=2013-07-21}}</ref>。
* [[软银|软银]]，每個月約處理10億件（2014年3月現在）的手機LOG情報，並用其改善手機訊號的訊號強度<ref>{{Cite book |language=ja |last= |first= |author=柴山和久 |authorlink= |coauthors= |year=2014 |title=ビッグデータを利益に変える方法 |publisher=幻冬舎 |page= |id= |isbn=978-4344952393 |quote= }}</ref>。
* 大企业对大数据技能需求量大，吸引了许多大学诸如[[加州大學柏克萊分校|伯克利大学]]开专门提供受过大数据训练的毕业者的大学部门。硅谷纽约为主《[[The_Data_Incubator|The Data Incubator]]》公司,2012年成立，焦点是[[数据科学|数据科学]]与大数据企业培训，提供国际大数据培训服务。

=== 社会学 ===
大資料产生的背景离不开Facebook等社交网络的兴起，人们每天通过这种自媒体传播信息或者沟通交流，由此产生的信息被网络记录下来，社会学家可以在这些数据的基础上分析人类的行为模式、交往方式等。美国的涂尔干计划就是依据个人在社交网络上的数据分析其自杀倾向，该计划从美军退役士兵中拣选受试者，透过Facebook的行动app收集资料，并将用户的活动数据传送到一个医疗资料库。收集完成的数据会接受人工智能系统分析，接著利用预测程式来即时监视受测者是否出现一般认为具伤害性的行為。

== 市場 ==
巨量資料的出現提升了對資訊管理專家的需求，[[Software_AG|Software AG]]、[[Oracle|Oracle]]、[[IBM|IBM]]、[[微軟|微軟]]、[[SAP公司|SAP]]、[[EMC|易安信]]、[[惠普|惠普]]和[[戴爾|戴爾]]已在多間資料管理分析專門公司上花費超過150億美元。在2010年，資料管理分析產業市值超過1,000億美元，並以每年將近10%的速度成長，是整個軟體產業成長速度的兩倍{{r|Economist}}。

經濟的開發成長促進了密集資料科技的使用。全世界共有約46億的行動電話用戶，並有10至20億人連結網際網路{{r|Economist}}。自1990年起至2005年間，全世界有超過10億人進入中產階級，收入的增加造成了識字率的提升，更進而帶動資訊量的成長。全世界透過[[電信|電信]]網路交換資訊的容量在1986年為281[[拍字节|兆億位元組]]（PB），1993年為471兆億位元組，2000年時增長為2.2[[艾位元組|艾位元組]]（EB），在2007年則為65艾位元組<ref name="HilbertLopez2011"/>。根據預測，在2013年網際網路每年的資訊流量將會達到667艾位元組{{r|Economist}}。

== 相關條目 ==
{{Portal box|资讯科技}}
{{div col|cols=3}}
*[[資料探勘|資料探勘]]
*[[資料庫|資料庫]]
*[[对象数据库|对象数据库]]
*[[关系数据库|关系数据库]]
*[[統計學|統計學]]
*[[商務智能|商務智能]]
*[[分布式计算|分布式计算]]、[[分布式数据库|分布式数据库]]、[[分散式檔案系統|分散式檔案系統]]、[[分散式運算環境|分散式運算環境]]
*[[超级计算机|超级计算机]]
*[[运筹学|运筹学]]
*[[MapReduce|MapReduce]]
*[[合成作戰中心|合成作戰中心]]
*[[工業大數據|工業大數據]]
*[[云计算|云计算]]
{{div col end}}

== 注释 ==
{{Reflist|group=原文}}

== 参考文献 ==
{{Reflist
|colwidth = 35em
|refs =
<ref name="Economist">{{cite news |title=Data, data everywhere |url = http://www.economist.com/node/15557443 |newspaper=The Economist |date=2010-02-25 |accessdate=2012-12-09 }}</ref>
}}

== 延伸閱讀 ==
* {{cite web|url=http://www.odbms.org/download/BigDataforGood.pdf|title=Big Data for Good|publisher=ODBMS.org|date=2012-06-05|accessdate=2013-11-12}}
* {{cite journal
 | last1 = Hilbert
 | first1 = Martin
 | first2 = Priscila |last2=López
 | title = The World's Technological Capacity to Store, Communicate, and Compute Information
 | journal = Science
 | volume = 332
 | issue = 6025
 | pages = 60–65
 | year = 2011
 | doi = 10.1126/science.1200970
 | pmid = 21310967 |url=http://martinhilbert.net/WorldInfoCapacity.html |ref=harv
}}
* {{cite web|url=http://www.ge-ip.com/library/detail/13476/?cid=wiki_Rise_of_Industrial_Big_Data|title=The Rise of Industrial Big Data|publisher=GE Intelligent Platforms|accessdate=2013-11-12}}
*ISBN 978-986-320-191-5 《大-{數據}-》
*ISBN 978-986-241-673-0 《雲端時代的殺手級應用：Big Data巨量資料分析》
* {{cite web|url=http://www.engr.sjsu.edu/gaojerry/IEEEBigDataService|title=IEEE Big Data Service|publisher=ODBMS.org|date=2014-09-07|accessdate=2014-09-07}}

== 外部連結 ==
{{Commons category|Big data}}
{{Wiktionary|big data}}
* [https://web.archive.org/web/20140227020937/http://www.wired.tw/events/big_data_magzine 巨量資料的相關報導文章] （《Wired》中文網站）
* [http://web.mit.edu/professional/onlinex-programs/courses/tackling_the_challenges_of_big_data.html 處理巨量資料的挑戰]（美國麻省理工學院線上課程）

<!--　以下是相關导航模板，也請保留這段註解不要刪除。　-->
{{-}}
{{Computer Science}}

 <!--　以下列表是分類，也請保留這段註解不要刪除。　-->
[[Category:資訊科學|Category:資訊科學]]
[[Category:資料庫|Category:資料庫]]
[[Category:數據挖掘|Category:數據挖掘]]
[[Category:電腦數據|Category:電腦數據]]
[[Category:電腦架構|Category:電腦架構]]
[[Category:計算機科學|Category:計算機科學]]
[[分類:信息革命|分類:信息革命]]
[[Category:大數據|Category:大數據]]