{{refimprove|time=2012-05-20T00:38:08+00:00}}
'''大间隔最近邻居（{{lang|en|Large margin nearest neighbor (LMNN)}}）'''分类算法是[[统计学|统计学]]的一种[[机器学习算法|机器学习算法]]。该算法是在<math>k</math>近邻分类其中学习一种欧式距离度量[[函数|函数]]。该度量函数优化的目标是：对于一个输入<math>x_i</math> 的<math>k</math>个近邻都属于同一类别，而不同类别的样本与<math>x_i</math>保持一定大的距离。<math>k</math>近邻规则是模式识别领域广泛使用的一种简单有效的方法。它的效果的好坏只依赖于确定最近邻的距离度量。基于欧式距离度量学习函数的大间隔最近邻居分类算法能够很好的改善<math>k</math>近邻算法分类效果。<ref name="Weinberger05">{{cite journal
 | last = Weinberger
 | first = K. Q.
 | coauthors = Blitzer J. C., Saul L. K.
 | title = Distance Metric Learning for Large Margin Nearest Neighbor Classification,
 | journal = Advances in Neural Information Processing Systems 18 (NIPS)
 | year=2006
 | pages=1473–1480
 | url=http://books.nips.cc/papers/files/nips18/NIPS2005_0265.pdf
}}</ref>

== 定义 ==
大间隔最近邻居算法的主要想法就是通过学习一种距离度量使得在一个新的转换空间中，对于一个输入<math>x_i</math> 的<math>k</math>个近邻都属于同一类别，而不同类别的样本与<math>x_i</math>保持一定大的距离。如果该想法能够实现则留一（LOO）分类错误率将会最小化。该算法的最主要的任务就是求得满足条件的线性空间转换矩阵<math>M</math>。
定义有类别标签的训练数据集为：<math> D=\{(\vec x_1,y_1),\dots,(\vec x_n,y_n)\}\subset R^d\times C</math>, 其中类别标签集为：<math>C=\{1,\dots,c\}</math>. 
我们的目标是学习一种用来估计如下平方距离的线性变换<math>M</math>：
<math>d(\vec x_i,\vec x_j)=(\vec x_i-\vec x_j)^\top\mathbf{M}(\vec x_i-\vec x_j)</math>

其中<math>M</math>是半正定矩阵。欧氏距离是该距离度量的特例（<math>M</math>为单位矩阵的形式）。该度量算法也被称作是马氏距离度量（{{lang|en|Mahalanobis Metric}}）。
图1显示了，该算法的学习过程：
[[File:Lmnn.png|thumb]]

=== 目标邻居的定义 ===
对于每一个输入样本<math>x_i</math>，除了要知道其类别标签<math>y_i</math>外，还需要确定其<math>k</math>个目标邻居，即<math>k</math>个同类别的输入，并且希望通过上式求出的距离最小。当缺乏先验知识的话，属于同类别的目标邻居可以由欧氏距离确定。则属于同类别的<math>k</math>个的输入即为目标邻居。

=== 入侵样本的定义 ===
对于任何一个输入样本<math>x_i</math>，其入侵样本是指与其最近邻的<math>k</math>个样本中与其不同类的样本。该算法在对训练样本学习过程中应尽可能的使入侵样本的数目达到最小化。

== 算法 ==
大间隔最近邻居算法的转换矩阵<math>M</math>可以通过半定规划得到优化。该算法的目标是：对于每一个输入样本，其<math>k</math>个目标邻居应尽可能的接近，而那些入侵样本应尽可能的远离该输入样本（即与其保持一定大的距离间隔）。图1显示了该算法的学习过程，通过学习使得输入向量<math>x_i</math>被其目标近邻包围。对于一个测试样本，我们取<math>k</math>为3的最近邻规则。
第一个优化的目标是实现输入样本<math>x_i</math>与其目标近邻的平均距离的最小化:
<math>\sum_{i,j\in N_i} d(\vec x_i,\vec x_j)</math>.

第二个优化的目标是使输入样本<math>x_i</math>到其目标邻居的距离与其到入侵近邻的距离至少保持1个单位的间隔。该约束可以表示为：
<math>\forall_{i,j \in N_i,l, y_l\neq y_i} d(\vec x_i,\vec x_j)+1\leq d(\vec x_i,\vec x_l)</math>

因此，最终的优化问题可以表示为：

:<math> \min_{\mathbf{M}} \sum_{i,j\in N_i} d(\vec x_i,\vec x_j) + \sum_{i,j,l} \xi_{ijl}</math>
:<math>\forall_{i,j \in N_i,l, y_l\neq y_i} </math>
:<math>   d(\vec x_i,\vec x_j)+1\leq d(\vec x_i,\vec x_l)+\xi_{ijl}</math>
:<math> \xi_{ijl}\geq 0</math>
:<math> \mathbf{M}\succeq 0</math>
其中<math>M</math>为半定矩阵。

== 参考文章 ==
{{reflist}}

== 相关链接 ==
* [http://www.cse.wustl.edu/~kilian/code/code.html Matlab Implementation]
* [https://web.archive.org/web/20110429021554/http://www.cs.berkeley.edu/~kulis/icml2010_tutorial.htm ICML 2010 Tutorial on Metric Learning]

[[Category:机器学习|D]]