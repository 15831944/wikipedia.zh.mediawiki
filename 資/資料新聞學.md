'''資料新聞學（台湾的叫法，在中国大陆称之为数据新闻）'''是指透過對大量資料集進行分析與篩檢後來產出新聞報導（故事）的一種新聞處理程序。在資料新聞學中，我們常常會使用到網路上可自由取得的[[開放資料|開放資料]]，然後使用[[開放原始碼軟體|開放原始碼軟體]]來處理分析<ref>{{cite web |author=Lorenz, Mirko |url=http://datadrivenjournalism.net/ |title=Data driven journalism: What is there to learn? |work=Edited conference documentation, based on presentations of participants |date=2010-08-24 |location=荷蘭阿姆斯特丹 |accessdate=2012-11-18}}</ref>。資料新聞學希望能服務大眾、協助消費者、經理管理人、政治人物來了解固定出現的模式，並根據出現的現像擬定策略。因此，資料新聞學將會使新聞記者在社會上扮演新的角色。

==定義==
[[File:Data_driven_journalism_process.jpg|thumb]]

根據資訊架構師和多媒體新聞記者 Mirko Lorenz 的說法，資訊新聞學是一個包含了下列這些元素的完整 ''workflow'' (工作流程) :將資料純淨化、結構化來「深入資料」，挖掘特定資訊來「過濾資料」，再將資料「視覺化」以做出報導。<ref>Lorenz, Mirko. (2010). [http://www.slideshare.net/mirkolorenz/datadriven-journalism-what-is-there-to-learn Data driven journalism: What is there to learn?] Presented at IJ-7 Innovation Journalism Conference, 7–9 June 2010, Stanford, CA</ref>另外也可以將這個過處理過程擴充加入其他步驟，使其適用於個人層面或是更廣的公共層面。 

資料新聞學訓練員暨作家Paul Bradshaw用一種類似的方式來描述這種資料導向的新聞工作：必須要能夠使用像是[[MySQL|MySQL]]或是[[Python|Python]]等資料處理軟體來「找到」資料；然後「訊問」它，也就是要能夠理解當中的術語以及統計學；最後藉由開放原始碼工具將其「視覺化」及「混搭」。<ref>Bradshaw, Paul (1 October 2010). [http://www.guardian.co.uk/news/datablog/2010/oct/01/data-journalism-how-to-guide How to be a data journalist]. ''The Guardian''</ref>

另外一個以結果導向來定義這個詞的資料記者暨網路趨勢研究者(web strategist)Henk van Ess (2012)<ref>van Ess, Henk. (2012). [http://www.slideshare.net/searchbistro/the-gory-details-of-datajournalism-what-went-wrong-and-who-was-responsible-by-henk-van-ess Gory details of data driven journalism]</ref>認為「資料導向的新聞工作使得記者能夠找到尚未被發現的事件，或是透過這套搜尋資料的流程來找到新的角度完成這份報導，也就是運用可行的開放原始碼工具對這些資料（可能是任何形式）加工並呈現出來。」Van Ess 認為一些資料導向的工作流程會使其產品「不在好敘事的範疇裡」，因為做出來的結果在於強調問題，而非闡述問題。「一個好的資料導向生產流程擁有不同的層面。它不只能夠讓你找到只對你重要，且個人化的內容，還能夠鑽到相關的細節裡讓你能夠廣覽全局。」


{{-}}
{{TransH}}
==基於資料的新聞報導==
Telling stories based on the data is the primary goal. The findings from data can be transformed into any form of [[journalistic_writing|journalistic writing]]. Visualizations can be used to create a clear understanding of a complex situation. Furthermore, elements of storytelling can be used to illustrate what the findings actually mean, from the perspective of someone who is affected by a development. This connection between data and story can be viewed as a "new arc" trying to span the gap between developments that are relevant, but poorly understood, to a story that is verifiable, trustworthy, relevant and easy to remember.

==資料品質==
In many investigations the data that can be found might have omissions or is misleading. As one layer of data-driven journalism a critical examination of the data quality is important. In other cases the data might not be public or is not in the right format for further analysis, e.g. is only available in a [[Portable_Document_Format|PDF]]. Here the process of data-driven journalism can turn into stories about data quality or refusals to provide the data by institutions. As the practice as a whole is in early development steps, examinations of data sources, data sets, data quality and data format are therefore an equally important part of this work. 

===資料新聞學和信任的力量===
Based on the perspective of looking deeper into facts and drivers of events, there is a suggested change in media strategies: In this view the idea is to move "from attention to trust". The creation of attention, which has been a pillar of media business models has lost its relevance because reports of new events are often faster distributed via new platforms such as Twitter than through traditional media channels. On the other hand, trust can be understood as a scarce resource. While distributing information is much easier and faster via the web, the abundance of offerings creates costs to verify and check the content of any story create an opportunity. The view to transform media companies into trusted data hubs has been described in an article cross-published in February 2011 on Owni.eu<ref>{{cite web |url=http://owni.eu/2011/02/28/media-companies-must-become-trusted-data-hubs-catering-to-the-trust-market/ |title=存档副本 |accessdate=2011-08-17 |deadurl=yes |archiveurl=https://web.archive.org/web/20110824045435/http://owni.eu/2011/02/28/media-companies-must-become-trusted-data-hubs-catering-to-the-trust-market/ |archivedate=2011-08-24 }}</ref> and Nieman Lab.<ref>http://www.niemanlab.org/2011/03/voices-news-organizations-must-become-hubs-of-trusted-data-in-an-market-seeking-and-valuing-trust/</ref>

==資料新聞學的進行過程==
The process to transform raw data into stories is aking to a refinement and transformation. The main goal is to extract information recipients can act upon. The task of a data journalist is to extract what is hidden. This approach can be applied to almost any context, such as finances, health, environment or other areas of public interest.

=== ''倒金字塔資料新聞學'' ===
In 2011, Paul Bradshaw introduced a model, he called [http://onlinejournalismblog.com/2011/07/07/the-inverted-pyramid-of-data-journalism/ "The Inverted Pyramid of Data Journalism"].

=== 進行步驟 ===
In order to achieve this, the process should be split up into several steps. While the steps leading to results can differ, a basic distinction can be made by looking at six phases:
# Find: Searching for data on the web
# Clean: Process to filter and transform data, preparation for visualization
# Visualize: Displaying the pattern, either as a static or animated visual
# Publish: Integrating the visuals, attaching data to stories
# Distribute: Enabling access on a variety of devices, such as the web, tablets and mobile
# Measure: Tracking usage of data stories over time and across the spectrum of uses.

=== 步驟描述 ===
==== 尋找資料 ====
Data can be obtained directly from governmental databases such as [[data.gov|data.gov]], [[data.gov.uk|data.gov.uk]] and World Bank Data API<ref>[http://data.worldbank.org/developers World Bank Data API]</ref> but also by placing [[Freedom_of_Information_request|Freedom of Information request]]s to government agencies; some requests are made and aggregated on websites like the UK's What Do They Know. While there is a worldwide trend towards opening data, there are national differences as to what extend that information is freely available in usable formats. If the data is in a webpage, scrapers are used to generate a spreadsheet. Examples of scrapers are: [[ScraperWiki|ScraperWiki]], Firefox plugin [[OutWit_Hub|OutWit Hub]] or [[Needlebase|Needlebase]] (note: Needlebase will be retired June 1, 2012<ref>http://needlebase.com/{{dead link|date=2018年4月 |bot=InternetArchiveBot |fix-attempted=yes }} (accessed February 10, 2012)</ref>). In other cases OCR-Software can be used to get data from PDFs.

Data can also be created by the public through crowd sourcing, as shown in March 2012 at the Datajournalism Conference in Hamburg by Henk van Ess <ref>http://www.slideshare.net/searchbistro/harvesting-knowledge-how-to-crowdsource-in-2010/ </ref>

==== 資料清洗 ====
Usually data is not in a format that is easy to visualize. Examples being that there are too many data points or that the rows and columns need to be sorted differently. Another issue is that once investigated many datasets need to be cleaned, structured and transformed. Various [[open_source|open source]] tools like [[Google_Refine|Google Refine]], [[Data_Wrangler|Data Wrangler]] and [[Google_Spreadsheet|Google Spreadsheet]]s<ref>http://blog.ouseful.info/2008/10/14/data-scraping-wikipedia-with-google-spreadsheets/</ref> allow uploading, extracting or formatting data.

==== 資料視覺化 ====
To visualize data in the form of graphs and charts, applications such as [[Many_Eyes|Many Eyes]] or [[Tableau_Public|Tableau Public]] are available. [[Yahoo!_Pipes|Yahoo! Pipes]] and Open Heat Map<ref>http://www.openheatmap.com/</ref> are examples of tools that enable the creation of maps based on data spreadsheets. The number of options and platforms is expanding. Some new offerings provide options to search, display and embed data, an example being [[Timetric|Timetric]].<ref>http://timetric.com/</ref> 

To create meaningful and relevant visualizations, journalists use a growing number of tools. There are by now, several descriptions what to look for and how to do it. Most notable published articles are:

* Joel Gunter: #ijf11: [http://blogs.journalism.co.uk/editors/2011/04/16/ijf11-lessons-in-data-journalism-from-the-new-york-times/ Lessons in data journalism from the New York Times, published on Journalism.co.uk] (April 16, 2011)<ref>http://blogs.journalism.co.uk/editors/2011/04/16/ijf11-lessons-in-data-journalism-from-the-new-york-times/</ref>
* Steve Myers: [http://www.poynter.org/latest-news/top-stories/95154/using-data-visualization-as-a-reporting-tool-can-reveal-storys-shape/ Using Data Visualization as a Reporting Tool Can Reveal Story’s Shape], published on Poynter (April 10, 2009, updated March 4, 2011), including a link to a tutorial by Sarah Cohen<ref>http://www.poynter.org/latest-news/top-stories/95154/using-data-visualization-as-a-reporting-tool-can-reveal-storys-shape/</ref>

As of 2011, the use of HTML 5 libraries using the [[canvas|canvas]] tag is gaining in popularity.  There are numerous libraries enabling to graph data in a growing variety of forms. One example here would be [http://www.rgraph.net/ RGraph].<ref>http://www.rgraph.net/</ref> As of 2011 there is a growing list of [http://sixrevisions.com/javascript/20-fresh-javascript-data-visualization-libraries/ JavaScript libraries] allowing to visualize data.

====出版資料故事====
There are different options to publish data and visualizations. A basic approach is to attach the data to single stories, similar to embedding web videos. More advanced concepts allow to create single dossiers, e.g. to display a number of visualizations, articles and links to the data on one page. Often such specials have to be coded individually, as many Content Management Systems are designed to display single posts based on the date of publication.

====散佈資料====
Providing access to existing data is another phase, which is gaining importance. Think of the sites as "marketplaces" (commercial or not), where datasets can be found easily by others. 
Especially of the insights for an article where gained from Open Data, journalists should provide a link to the data they used for others to investigate (potentially starting another cycle of interogation, leading to new insights).

Providing access to data and enabling groups to discuss what information could be extracted is the main idea behind [https://web.archive.org/web/20110812235741/http://buzzdata.com/ Buzzdata],<ref>{{cite web |url=http://buzzdata.com/ |title=存档副本 |accessdate=2011-08-17 |deadurl=yes |archiveurl=https://web.archive.org/web/20110812235741/http://buzzdata.com/ |archivedate=2011-08-12 }}</ref> a site using the concepts of social media such as sharing and following to create a community for data investigations. 

Other platforms (which can be used both to gather or to distribute data):
*  [http://helpmeinvestigate.com/ Help Me Investigate] (created by Paul Bradshaw)<ref>http://helpmeinvestigate.com/</ref>
*  [http://www.kasabi.com/ Kasabi], (currently in public beta, Aug. 2011)<ref>http://www.kasabi.com/</ref>
* [http://timetric.com/ Timetric]<ref>http://www.timetric.com</ref>

====評量以資料說故事的影響====
A final step of the process is to measure how often a dataset or visualization is viewed. 

In the context of data-driven journalism, the extent of such tracking, such as collecting user data or any other information that could be used for marketing reasons or other uses beyond the control of the user, should be viewed as problematic.{{Says who|date=September 2012}} One newer, non-intrusive option to measure usage is a lightweight tracker called PixelPing. The tracker is the result of a project by [[ProPublica|ProPublica]] and [[DocumentCloud|DocumentCloud]].<ref>http://www.propublica.org/nerds/item/pixel-ping-a-nodejs-stats-tracker</ref> There is a corresponding back-end solution to collect the data. The software is open source and can be downloaded via GitHub.<ref>https://github.com/documentcloud/pixel-ping</ref>

==實例==
There is a growing list of examples how data-driven journalism can be applied:

* The Guardian, being one of the pioneering media companies in this space (see: [http://www.guardian.co.uk/news/datablog/2011/jul/28/data-journalism Data journalism at the Guardian: what is it and how do we do it?])<ref>Rogers, Simon (2011) http://www.guardian.co.uk/news/datablog/2011/jul/28/data-journalism</ref>, has compiled an extensive list of data stories, see: [http://www.guardian.co.uk/news/datablog/2011/jan/27/data-store-office-for-national-statistics All of our data journalism in one spreadsheet]<ref>Evans, Lisa (2011) http://www.guardian.co.uk/news/datablog/2011/jan/27/data-store-office-for-national-statistics</ref>

Other prominent uses of data driven journalism is related to the release by whistle-blower organization [[WikiLeaks|WikiLeaks]] of the [[2010_Afghan_War_documents_leak|Afghan War Diary]], a compendium of 91,000 secret military reports covering the war in Afghanistan from 2004 to 2010.<ref>[http://wardiary.wikileaks.org/ Kabul War Diary], 26 July 2010, ''WikiLeaks''</ref> Three global broadsheets, namely ''[[The_Guardian|The Guardian]]'', ''[[The_New_York_Times|The New York Times]]'' and ''[[Der_Spiegel|Der Spiegel]]'', dedicated extensive sections<ref>[http://www.guardian.co.uk/world/the-war-logs Afghanistan The War Logs], 26 July 2010, ''The Guardian''</ref><ref>[http://www.nytimes.com/interactive/world/war-logs.html The War Logs], 26 July 2010 ''The New York Times''</ref><ref>[http://www.spiegel.de/international/world/0,1518,708314,00.html The Afghanistan Protocol: Explosive Leaks Provide Image of War from Those Fighting It], 26 July 2010, ''Der Spiegel''</ref> to the documents; [[The_Guardian|The Guardian]]'s reporting included an interactive map pointing out the type, location and casualties caused by 16,000 [[Improvised_explosive_device|IED]] attacks,<ref>[http://www.guardian.co.uk/world/datablog/interactive/2010/jul/26/ied-afghanistan-war-logs Afghanistan war logs: IED attacks on civilians, coalition and Afghan troops], 26 July 2010, ''The Guardian''</ref> [[The_New_York_Times|The New York Times]] published a selection of reports that permits rolling over underlined text to reveal explanations of military terms,<ref>[http://www.nytimes.com/interactive/world/26warlogs.html Text From a Selection of the Secret Dispatches], 26 July 2010, ''The New York Times''</ref> while [[Der_Spiegel|Der Spiegel]] provided hybrid visualizations (containing both graphs and maps) on topics like the number deaths related to insurgent bomb attacks.<ref>[http://www.spiegel.de/international/world/bild-708314-114717.html Deathly Toll: Death as a result of insurgent bomb attacks], 26 July 2010, ''Der Spiegel''</ref>. For the [[Iraq_War_documents_leak|Iraq War logs release]], The Guardian used [[Google_Fusion_tables|Google Fusion tables]] to create an interactive map of every incident where someone died<ref>[http://www.guardian.co.uk/world/datablog/interactive/2010/oct/23/wikileaks-iraq-deaths-map Wikileaks Iraq war logs: every death mapped], 22 October 2010, ''Guardian Datablog''</ref>, a technique it used again in the [[England_riots|England riots]] of 2011.<ref>[http://www.guardian.co.uk/news/datablog/interactive/2011/aug/09/uk-riots-incident-map UK riots: every verified incident - interactive map], 11 August 2011, ''Guardian Datablog''</ref>
{{TransF}}
==參見==
* [[Database_journalism|Database journalism]]
* [[Computational_journalism|Computational journalism]]
* [[Open_science_data|Open science data]]
* [[開放原始碼|開放原始碼]]
* [[Open_knowledge|Open knowledge]]
* [[陽光法案|陽光法案]]
* [[信息可視化|信息可視化]]

==外部連結==
* [http://datadrivenjournalism.net/ DataDrivenJournalism.net]
* [http://datajournalismhandbook.org/ The Data Journalism Handbook] / [https://web.archive.org/web/20150420043441/http://wiki.opendata.tw/doku.php?id=dj%3Adjhandbook 「資料新聞學」手冊]
* [https://web.archive.org/web/20150703234308/http://www.datajournalismtw.com/ 資料新聞學，從零開始(網站)]

==參考文獻==
{{Reflist|2}}


[[Category:新聞學|Category:新聞學]]