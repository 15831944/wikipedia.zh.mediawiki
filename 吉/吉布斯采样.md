'''吉布斯采样'''（{{lang-en|Gibbs sampling}}）是[[统计学|统计学]]中用于[[马尔科夫蒙特卡洛|马尔科夫蒙特卡洛]]（MCMC）的一种算法，用于在难以直接采样时从某一多变量[[概率分布|概率分布]]中近似抽取样本序列。该序列可用于近似[[联合分布|联合分布]]、部分变量的[[边缘分布|边缘分布]]或计算[[积分|积分]]（如某一变量的[[期望值|期望值]]）。某些变量可能为已知变量，故对这些变量并不需要采样。

吉布斯采样常用于[[统计推断|统计推断]]（尤其是[[贝叶斯推断|贝叶斯推断]]）之中。这是一种[[随机化算法|随机化算法]]，与[[最大期望算法|最大期望算法]]等统计推断中的确定性算法相区别。与其他MCMC算法一样，吉布斯采样从[[马尔科夫链|马尔科夫链]]中抽取样本，可以看作是[[Metropolis–Hastings算法|Metropolis–Hastings算法]]的特例。

该算法的名称源于[[约西亚·威拉德·吉布斯|约西亚·威拉德·吉布斯]]，由{{le|斯图尔特·杰曼|Stuart Geman}}与{{le|唐纳德·杰曼|Donald Geman}}兄弟于1984年提出。<ref>{{Cite journal
 | first1=S. |last1=Geman
 | first2=D. |last2=Geman
 | title = Stochastic Relaxation, Gibbs Distributions, and the Bayesian Restoration of Images
 | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence
 | volume = 6 |issue=6
 | pages = 721–741
 | year = 1984
 | doi = 10.1109/TPAMI.1984.4767596
}}</ref>

== 算法 ==
吉布斯采样适用于条件分布比边缘分布更容易采样的多变量分布。假设我们需要从联合分布<math> p(x_1, \dots, x_n) </math>中抽取<math>\mathbf{X} = (x_1, \dots, x_n)</math>的<math>\left.k\right.</math>个样本。记第<math>i</math>个样本为<math>\mathbf{X}^{(i)} = \left(x_1^{(i)}, \dots, x_n^{(i)}\right)</math>。吉布斯采样的过程则为：
# 确定初始值<math>\mathbf{X}^{(1)}</math>。
# 假设已得到样本<math>\mathbf{X}^{(i)}</math>，记下一个样本为<math>\mathbf{X}^{(i+1)} = \left(x_1^{(i+1)}, x_2^{(i+1)}, \dots, x_n^{(i+1)}\right)</math>。于是可将其看作一个向量，对其中某一分量<math>x_j^{(i+1)}</math>，可通过在其他分量已知的条件下该分量的概率分布来抽取该分量。对于此条件概率，我们使用样本<math>\mathbf{X}^{(i+1)}</math>中已得到的分量<math>x_1^{(i+1)}</math>到<math>x_{j-1}^{(i+1)}</math>以及上一样本<math>\mathbf{X}^{(i)}</math>中的分量<math>x_{j+1}^{(i)}</math>到<math>x_n^{(i)}</math>，即<math>p\left(x_j^{(i+1)}|x_1^{(i+1)},\dots,x_{j-1}^{(i+1)},x_{j+1}^{(i)},\dots,x_n^{(i)}\right)</math>。
# 重复上述过程<math>k</math>次。

在采样完成后，我们可以用这些样本来近似所有变量的联合分布。如果仅考虑其中部分变量，则可以得到这些变量的边缘分布。此外，我们还可以对所有样本求某一变量的平均值来估计该变量的期望。

== 参考文献 ==
{{reflist}}
* {{Citation
  | last1 = Bishop   | first1 = Christopher M.
  | title = Pattern Recognition and Machine Learning
  | year = 2006
  | publisher = Springer
  | ref = CITEREFBishop2006
  | isbn = 0-387-31073-8
  }}
* Bolstad, William M. (2010), ''Understanding Computational Bayesian Statistics'', John Wiley {{ISBN|978-0-470-04609-8}}
* {{Cite journal | doi = 10.2307/2685208| jstor = 2685208| title = Explaining the Gibbs Sampler| journal = The American Statistician| volume = 46| issue = 3| pages = 167| year = 1992| last1 = Casella | first1 = G. | last2 = George | first2 = E. I. }}
* {{Citation
 |first1=Alan E. |last1=Gelfand
 |first2=Adrian F. M. |last2=Smith
 |title=Sampling-Based Approaches to Calculating Marginal Densities
 |journal=Journal of the American Statistical Association
 |volume=85 |issue=410 |pages=398–409 |year=1990
 |mr=1141740 |doi=10.2307/2289776
 |jstor=2289776
}}
* Gelman, A., Carlin J. B., Stern H. S., Dunson D., Vehtari A., Rubin D. B. (2013), ''Bayesian Data Analysis'', third edition. London: Chapman & Hall.
* Levin, David A.; Peres, Yuval; Wilmer, Elizabeth L. (2008), "[http://www.uoregon.edu/~dlevin/MARKOV/ Markov Chains and Mixing Times]", American Mathematical Society.
* Robert, C. P.; Casella, G. (2004), ''Monte Carlo Statistical Methods'' (second edition), Springer-Verlag.

[[Category:蒙地卡罗方法|Category:蒙地卡罗方法]]