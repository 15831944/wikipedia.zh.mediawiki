'''交叉驗證'''，有時亦稱'''循環估計'''<ref name="Kohavi95">{{cite journal | last = Kohavi| first = Ron | year = 1995 | title = A study of cross-validation and bootstrap for accuracy estimation and model selection | journal = Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence | url= http://citeseer.ist.psu.edu/kohavi95study.html | volume = 2 | issue = 12 | pages = 1137–1143}}(Morgan Kaufmann, San Mateo)</ref> <ref name="Chang92">Chang, J., Luo, Y., and Su, K. 1992. GPSM: a Generalized Probabilistic Semantic Model for ambiguity resolution. In Proceedings of the 30th Annual Meeting on Association For Computational Linguistics (Newark, Delaware, June 28 - July 02, 1992). Annual Meeting of the ACL. Association for Computational Linguistics, Morristown, NJ, 177-184</ref> <ref name="Devijver82">Devijver, P. A., and J. Kittler, Pattern Recognition: A Statistical Approach, Prentice-Hall, London, 1982</ref>，
是一種[[統計學|統計學]]上將[[数据|数据]][[樣本|樣本]][[集合划分|切割]]成較小子集的實用方法。於是可以先在一個子集上做分析，
而其它子集則用來做後續對此分析的確認及驗證。
一開始的子集被稱為''訓練集''。而其它的子集則被稱為''驗證集''或''測試集''。交叉驗證的目標是在訓練階段定義一组用于“測試”模型的數據集，以便減少像過擬合的問題，得到該模型將如何衍生到一個獨立的數據集的提示。

交叉驗證的理論是由{{tsl|en|Seymour Geisser|}}所開始的。
它對於防範根据数据建议的测试假设是非常重要的，
特別是當後續的[[樣本|樣本]]是危險、成本過高或科学上不适合时去搜集。

== 交叉验证的使用 ==
假设有个未知模型具有一个或多个待定的参数，且有一个数据集能够反映该模型的特征属性（训练集）。适应的过程是对模型的参数进行调整，以使模型尽可能反映训练集的特征。如果从同一个训练样本中选择独立的样本作为验证集合，当模型因训练集过小或参数不合适而产生过拟合时，验证集的测试予以反映。
交叉验证是一种预测模型拟合性能的方法。
== 常見的交叉驗證形式 ==

=== Holdout 驗證 ===

常識來說，Holdout 驗證並非一種交叉驗證，因為数据並沒有交叉使用。
隨機從最初的樣本中選出部分，形成交叉驗證数据，而剩餘的就當做訓練数据。
一般來說，少於原本樣本三分之一的数据被選做驗證数据。
<ref>{{cite web | title=Tutorial 12 | work=Decision Trees Interactive Tutorial and Resources | url=http://decisiontrees.net/node/36 | accessdate=2006-06-21 | deadurl=yes | archiveurl=https://web.archive.org/web/20060623055814/http://decisiontrees.net/node/36 | archivedate=2006-06-23 }}</ref>

=== ''K''-fold cross-validation ===

K次交叉验证，将训练集分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个子样本验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10次交叉验证是最常用的。

=== 留一驗證 ===<!-- This section is linked from [[数据挖掘|数据挖掘]] -->

正如名稱所建議，
留一驗證（'''Leave-One-Out Cross Validation, LOOCV'''）意指只使用原本樣本中的一項來當做驗證資料，
而剩餘的則留下來當做訓練資料。
這個步驟一直持續到每個樣本都被當做一次驗證資料。
事實上，這等同於 ''K''-fold 交叉驗證是一樣的，其中''K''為原本樣本個數。
在某些情況下是存在有效率的演算法，如使用{{tsl|en|kernel regression|}} 和{{tsl|en|Tikhonov regularization|}}。

== 誤差估計 ==
可以計算估計誤差。常見的誤差衡量標準是[[均方差|均方差]]和[[方根均方差|方根均方差]]，
分別為交叉驗證的[[方差|方差]]和[[標準差|標準差]]。

== 另見 ==
* [http://en.wikipedia.org/wiki/Resampling_(statistics) Resampling_(statistics)]
* {{tsl|en|Validation (drug manufacture)|}}
* {{tsl|en|Verification and Validation|}}

== 外部連結 ==
* [http://paul.luminos.nl/documents/show_document.php?d=198 Naive Bayes implementation with cross-validation in Visual Basic] (includes executable and source code)
* [http://www.cs.technion.ac.il/~ronbeg/gcv/index.html A generic k-fold cross-validation implementation] (free open source; includes a distributed version that can utilize multiple computers and in principle can speed up the running time by several orders of magnitude.)

== 參考文獻 ==

{{reflist}}
{{Template:統計學}}

[[Category:统计检验|Category:统计检验]]