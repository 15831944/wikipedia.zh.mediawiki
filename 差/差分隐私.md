{{校对翻译}}
{{专家}}
{{NoteTA
|G1=IT
}}
'''差分隐私'''（{{lang-en|'''differential privacy'''}}）是[[密码学|密码学]]中的一种手段，旨在提供一种当从{{le|统计数据库|Statistical database}}[[信息檢索|查询]]时，最大化数据查询的准确性，同时最大限度减少识别其{{tsl|en|Row (database)||记录}}的机会。

== 动机 ==
设想一个受信任的机构持有涉及众多人的敏感个人信息（例如医疗记录、观看记录或电子邮件统计）的[[数据集|数据集]]，但想提供一个全局性的统计数据。这样的系统被称为统计数据库。但是，提供有关数据的综合性统计也可能揭示一些涉及个人的信息。事实上，当研究人员链接两个或多个分别无害化处理的数据库来识别个人信息时，各种公共记录匿名化的特殊方法都失效了。而差分隐私就是为防护这类统计数据库脱匿名技术而形成的一个隐私框架。

=== Netflix奖 ===
举例来说，2006年10月，[[Netflix|Netflix]]提出一笔{{tsl|en|Netflix Prize||100万美元}}的奖金，作为将其推荐系统改进达10%的奖励。Netflix还发布了一个训练数据集供竞选开发者训练其系统。在发布此数据集时，Netflix提供了免责声明：为保护客户的隐私，可识别单个客户的所有个人信息已被删除，并且所有客户ID已用随机分配的ID [sic]替代。

Netflix不是网络上唯一的电影评级门户网站，其他网站还有很多，包括[[互联网电影数据库|IMDb]]。个人可以在IMDb上注册和评价电影，并且可以选择匿名化自己的详情。[[德克薩斯州大學奧斯汀分校|德克薩斯州大學奧斯汀分校]]的研究员{{le|Arvind Narayanan}}和Vitaly Shmatikov将Netflix匿名化的训练数据库与[[互联网电影数据库|IMDb]]数据库（根据用户评价日期）相连，能够部分反匿名化Netflix的训练数据库，危及到部分用户的身份信息。<ref>{{Cite conference
 | author = [[Arvind_Narayanan|Arvind Narayanan]], [[Vitaly_Shmatikov|Vitaly Shmatikov]]
 | title = Robust De-anonymization of Large Sparse Datasets
 | conference = [[IEEE_Symposium_on_Security_and_Privacy|IEEE Symposium on Security and Privacy]]
 | year = 2008 
 | pages = 111–125
 | url = https://www.cs.utexas.edu/~shmat/shmat_oak08netflix.pdf
}}</ref>

=== 马萨诸塞州集团保险委员会（GIC）医疗数据库事件 ===
[[卡内基梅隆大学|卡内基梅隆大学]]的{{le|Latanya Sweeney}}的将匿名化的GIC数据库（包含每位患者的出生日期、性别和邮政编码）与选民登记记录相连后，可以找出马萨诸塞州州长的[[病历|病历]]。

=== 元数据与流动数据库 ===
[[麻省理工学院|MIT]]的De Montjoye等人引入了{{tsl|en|Unicity distance||单一性}}（意为{{le|独特性|uniqueness}}）概念，显示出4个时空点、近似地点和时间就足以唯一性识别一个150万人流动数据库中的95%用户。<ref>{{Cite journal|title=Unique in the Crowd: The privacy bounds of human mobility|url=http://www.nature.com/srep/2013/130325/srep01376/full/srep01376.html|last=de Montjoye|first=Yves-Alexandre|last2=César A. Hidalgo|date=March 25, 2013|journal=Nature srep.|accessdate=12 April 2013|doi=10.1038/srep01376|last3=Michel Verleysen|last4=Vincent D. Blondel}}</ref>该研究进一步表明，即使数据集的分辨率较低，这些约束仍然存在，即粗糙或模糊的流动数据集和元数据也只提供很少的匿名性。

== 概要 ==

== 现实世界中对差分隐私的采用 ==
至今为止，比较知名的采用差分隐私的应用如下：
* 美国人口普查局，展示通勤模式
* Google的RAPPOR，用于遥测，例如了解统计劫持用户设置的恶意软件（[https://github.com/google/rappor RAPPOR's open-source implementation]）
* Google，分享历史流量统计信息。
* 2016年6月13日，[[蘋果公司|蘋果公司]]宣布其在[[iOS|iOS]] 10中使用差异隐私，以改进其虚拟助理和建议技术，<ref>{{Cite web|url=https://www.apple.com/pr/library/2016/06/13Apple-Previews-iOS-10-The-Biggest-iOS-Release-Ever.html|title=Apple - Press Info - Apple Previews iOS 10, the Biggest iOS Release Ever|accessdate=16 June 2016}}</ref>
* 在数据挖掘模型中使用差异隐私的实际表现已有一些初步研究。<ref>{{Cite journal|title=Differentially private random decision forests using smooth sensitivity|url=http://www.sciencedirect.com/science/article/pii/S0957417417300428|last=Fletcher|first=Sam|last2=Islam|first2=Md Zahidul|date=July 2017|journal=Expert Systems with Applications|doi=10.1016/j.eswa.2017.01.034|volume=78|pages=16–31}}</ref>

== 参见 ==
* {{le|Quasi-identifier}}
* {{le|Exponential mechanism (differential privacy)}}
* {{le|k-anonymity}}

== 参考资料 ==
{{Reflist|refs=
}}

== 外部链接 ==
* [https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/dwork.pdf Differential Privacy] by Cynthia Dwork, ICALP July 2006. 
* [http://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf The Algorithmic Foundations of Differential Privacy] by Cynthia Dwork and Aaron Roth, 2014. 
* [http://research.microsoft.com/apps/pubs/default.aspx?id=74339 Differential Privacy: A Survey of Results] by Cynthia Dwork, Microsoft Research, April 2008
* [http://video.ias.edu/csdm/dynamicdata Privacy of Dynamic Data: Continual Observation and Pan Privacy] by Moni Naor, Institute for Advanced Study, November 2009
* [http://simons.berkeley.edu/talks/katrina-ligett-2013-12-11 Tutorial on Differential Privacy] by Katrina Ligett, California Institute of Technology, December 2013
* [http://www.cerias.purdue.edu/news_and_events/events/security_seminar/details/index/j9cvs3as2h1qds1jrdqfdc3hu8 A Practical Beginner's Guide To Differential Privacy] by Christine Task, Purdue University, April 2012 
* [http://blog.myplaceinthecrowd.org/2011/04/27/the-cdp-private-map-maker-v0-2/ Private Map Maker v0.2] on the Common Data Project blog
* [https://research.googleblog.com/2014/10/learning-statistics-with-privacy-aided.html Learning Statistics with Privacy, aided by the Flip of a Coin] by Úlfar Erlingsson, Google Research Blog, October 2014

[[Category:密码学理论|Category:密码学理论]]
[[Category:信息隐私|Category:信息隐私]]