<!--{{about|automata that learn|computational approaches to learn regular automata|Induction of regular languages}}-->
'''學習自動機'''（learning automaton）是一種1970年代就開始研究的[[机器学习|机器学习]]演算法。學習自動機是由對以往對環境的經驗來選擇目前的動作。若環境是[[随机过程|随机性]]的，且使用了[[馬可夫決策過程|馬可夫決策過程]]，則這種學習自動機屬於[[强化学习|强化学习]]的演算法。

== 歷史 ==
學習自動機的研究可以追溯到蘇聯的{{link-en|Michael Lvovitch Tsetlin|Michael Lvovitch Tsetlin}}在1960年代所做的研究。他和同事們發表了數篇論文，說明如何用矩陣來描述自動機功能。此外，Tsetlin也在研究合理及集体性的自动机行为，以及自动机游戏的。美國學者在1960年代也有探討學習自動機。不過一直到1974年Narendra及Thathachar在一调查报告中才開始使用「learning automaton」此一名詞。

== 定義 ==
學習自動機是在一隨機環境下的適應性決策產生單元，可以根據和環境重複的互動來學習最佳的動作。動作是依照特定的[[機率分佈|機率分佈]]來決定，而系統會依採取特定行動後的環境反應來更新機率分佈。

在[[强化学习|强化学习]]的領域中，學習自動機的特徵是[[馬可夫決策過程|馬可夫決策過程]]。政策迭代者會直接處理π，這點其他强化学习的演算法不同。另一個政策迭代者的例子是{{link-en|演化演算法|evolutionary algorithm}}。

形式上，Narendra和Thathachar用以下的方式定義隨機自動機
* ''x''為可能輸入的集合
* Φ = { Φ<sub>1</sub>, ..., Φ<sub>''s''</sub> } 是可能內部狀態的集合
* a set α = { α<sub>1</sub>, ..., α<sub>''r''</sub> } 是可能輸出或是動作的集合，''r''≤''s'',
* 初始的狀態機率向量''p(0)'' = ≪ ''p''<sub>1</sub>(0), ..., ''p''<sub>''s''</sub>(0) ≫,
* [[可计算函数|可计算函数]] ''A'' ，在每一個時間''t''，根據從''p''(''t'')、當時輸入及狀態來產生''p''(''t''+1) * 函數''G'': Φ → α，在每一個時間產生輸出
在其論文中，只探討''r''=''s''，也就是''G''是[[双射|双射]]的學習自動機，因此可能會混淆內部狀態及動作。

自動機的狀態是對應離散狀態離散參數[[马尔可夫链|马尔可夫链]]的狀態<ref>(Narendra, Thathachar, 1974) p.325 left</ref>。<!---以下敘述部份是用一般的有限狀態自動機所猜測的，因為Narendra和Thathachar在這部份沒有明確說明
--->在每一個時間點''t''=0,1,2,3,...，自動機會從環境讀取輸入，用''A''來將''p''(''t'')更新為''p''(''t''+1)，根據機率分布''p''(''t''+1)選擇後續狀態，並輸出其動作，而環境會讀取其動作，其結果就是下一個時間的環境輸入。<!---猜測結束
--->常常會選用輸入集合''x'' = { 0,1 }，其中的0和1對應環境「不懲罰」及「懲罰」的反應。因此學習自動機的目的是使「懲罰」的反應的數量降到最低，這種自動機和環境之間的回授迴路稱為P-模型。而Q-模型允許''x''是有限集合中的任意值，S-模型是允許''x''為[[區間|區間]] [0,1]中的[[实数|实数]]為<ref>(Narendra, Thathachar, 1974) p.325 right</ref>。

==有限動作集學習自動機 ==
有限動作集學習自動機（Finite action-set learning automata、FALA）是可能動作數量有限的學習自動機，若用較數學的說法來表示，是動作集合大小為有限值的學習自動機<ref name="Thathachar2002">{{cite journal|last1=Thathachar|first1=M.A.L.|last2=Sastry|first2=P.S.|title=Varieties of learning automata: an overview|journal=IEEE Transactions on Systems, Man and Cybernetics, Part B (Cybernetics)|date=December 2002|volume=32|issue=6|pages=711–722|doi=10.1109/TSMCB.2002.1049606}}</ref>。

==相關條目==
*[[强化学习|强化学习]]
*[[博弈论|博弈论]]
*[[自動機理論|自動機理論]]

== 文獻 ==
* Philip Aranzulla and John Mellor <!---
---Trying to flesh out the previous poor reference hint, I found Mellor's home page and added all publications of Mellor+Aranzulla found there. They seem to fit not very well into this article, however.---
--->([https://web.archive.org/web/20131203032954/http://www.bradford.ac.uk/scim/staff-profiles/profile/?u=jemellor Home page]):
** Mellor J and Aranzulla P (2000): "Using an S-Model Response Environment with Learnng Automata Based Routing Schemes for IP Networks ", Proc. Eighth IFIP Workshop on Performance Modelling and Evaluation of ATM and IP Networks, pp 56/1-56/12, Ilkley, UK.
** Aranzulla P and Mellor J (1997): "Comparing two routing algorithms requiring reduced signalling when applied to ATM networks", Proc. Fourteenth UK Teletraffic Symposium on Performance Engineering in Information Systems, pp 20/1-20/4, UMIST, Manchester, UK.
* {{cite journal|authors=Narendra K., Thathachar M.A.L.|title=Learning automata – a survey|journal=IEEE Transactions on Systems, Man, and Cybernetics|date=July 1974| volume= SMC-4| issue=4| pages=323–334| url=http://www.dklevine.com/archive/refs4481.pdf| doi=10.1109/tsmc.1974.5408453}}
* Mikhail L’vovich TSetlin., ''Automaton Theory and the Modelling of Biological Systems'', New York and London, Academic Press, 1973. ([http://www.worldcatlibraries.org/wcpa/ow/4f39ba3751b2260c.html Find in a library])

==参考资料==
{{reflist}}

[[Category:机器学习|Category:机器学习]]
[[Category:控制理论|Category:控制理论]]