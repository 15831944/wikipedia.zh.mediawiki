{{NoteTA
| T = zh-cn:黑塞矩阵; zh-tw:黑塞矩陣; zh-hk:黑塞矩陣
}}

'''黑塞矩阵'''（德语：Hesse-Matrix；英语：{{lang|en|Hessian matrix}} 或 {{lang|en|Hessian}}），又译作'''海森矩阵'''、'''海塞矩阵'''或'''海瑟矩阵'''，是一个以德国数学家[[奥托·黑塞|奥托·黑塞]]命名的多变量实值函数的二阶[[偏导数|偏导数]]组成的[[方块矩阵|方块矩阵]]，假設有一實數函数 <math>\textstyle f(x_1, x_2, \dots, x_n),</math>如果 <math>f</math> 所有的二阶偏导数都存在，那么 <math>f</math> 的黑塞矩阵的第 <math>ij</math>-項即：

:<math>H(f)_{ij}(x) = D_i D_j f(x)</math>
其中<math>x = (x_1, x_2, \dots, x_n)</math>，即
:<math>H(f) = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1\,\partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_1\,\partial x_n} \\  \\
\frac{\partial^2 f}{\partial x_2\,\partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots & \frac{\partial^2 f}{\partial x_2\,\partial x_n} \\  \\
\vdots & \vdots & \ddots & \vdots \\  \\
\frac{\partial^2 f}{\partial x_n\,\partial x_1} & \frac{\partial^2 f}{\partial x_n\,\partial x_2} & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}</math>

（也有人把黑塞定义为以上矩阵的[[行列式|行列式]]<ref>{{cite book |last1=Binmore |first1=Ken |authorlink1=Kenneth Binmore |last2=Davies |first2=Joan |year=2007 |title=Calculus Concepts and Methods |oclc=717598615 |isbn=9780521775410 |publisher=Cambridge University Press|page=190 }}</ref>。）

黑塞矩阵被应用于[[牛顿法|牛顿法]]解决的大规模优化问题。

== 混合偏导数和黑塞矩阵的对称性 ==
黑塞矩阵的混合偏导数是黑塞矩阵非主对角线上的元素。假如他们是连续的，那么求导顺序没有区别，即
:<math>\frac {\partial}{\partial x} \left( \frac { \partial f }{ \partial y} \right) =
       \frac {\partial}{\partial y} \left( \frac { \partial f }{ \partial x} \right)</math>
上式也可写为
:<math>f_'{xy} = f_'{yx} \,</math>

也就是說，如果''f'' 函数在区域''D'' 内的每個二阶导数都是連續函數，那么''f''的黑塞矩阵在''D''区域内为[[对称矩阵|对称矩阵]]。

== 在映射 <math>f: \mathbb{R}^2 \to \mathbb{R}</math> 的應用 ==
給定二階導數連續的[[映射|映射]]<math>f: \mathbb{R}^2 \to \mathbb{R}</math>，黑塞矩陣的行列式，可用於分辨<math>f</math>的臨界點是屬於[[鞍點|鞍點]]還是[[極值点|極值点]]。

對於<math>f</math>的臨界點<math>(x_0, y_0)</math>一點，有<math> \frac{\partial f(x_0, y_0)}{\partial x} = \frac{\partial f(x_0, y_0)}{\partial y} = 0</math>，然而憑一階導數不能判斷它是鞍點、局部極大點還是局部極小點。黑塞矩陣可能解答這個問題。

: <math>
H = \begin{vmatrix}
\frac{\partial^2 f}{\partial x^2} & \frac{\partial^2 f}{\partial x\,\partial y} \\ \\
\frac{\partial^2 f}{\partial y\,\partial x} & \frac{\partial^2 f}{\partial y^2}
 \end{vmatrix} = \frac{\partial^2 f}{\partial x^2} \frac{\partial^2 f}{\partial y^2} - (\frac{\partial^2 f}{\partial y\,\partial x})^2
</math>

* H > 0：若<math>\frac{\partial^2 f}{\partial x^2} > 0</math>，則<math>(x_0, y_0)</math>是局部極小點；若<math>\frac{\partial^2 f}{\partial x^2} < 0</math>，則<math>(x_0, y_0)</math>是局部極大點。
* H < 0：<math>(x_0, y_0)</math>是鞍點。
* H = 0：二階導數無法判斷該臨界點的性質，得從更高階的導數以[[泰勒公式|泰勒公式]]考慮。

===在高维情况下的推广===
当[[函数|函数]]<math>f: \mathbb{R}^n \to \mathbb{R}</math>二阶连续可导时，Hessian矩阵H在临界点<math>x_0</math>上是一个<math>n\times n</math>阶的对称矩阵。

* 当H是[[正定矩阵|正定矩阵]]时，临界点<math>x_0</math>是一个局部的极小值。
* 当H是[[负定矩阵|负定矩阵]]时，临界点<math>x_0</math>是一个局部的极大值。
* H=0,需要更高阶的导数来帮助判断。
* 在其余情况下，临界点<math>x_0</math>不是局部极值。

==参看==
* [[雅可比矩阵|雅可比矩阵]]

== 参考文献 ==
{{reflist}}

[[Category:矩陣|H]]
[[Category:多变量微积分|H]]