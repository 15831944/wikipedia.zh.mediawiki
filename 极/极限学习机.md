{{about|机器学习中的一种'''人工神经网络模型'''|教育类电子产品学习机|小霸王 (公司)}}
{{机器学习导航栏}}
'''极限学习机'''（[[英文|英文]]：Extreme Learning Machines，縮寫ELM），又名'''超限学习机'''，為[[人工智能|人工智能]][[機器學習|機器學習]]領域中的一種[[人工神經網絡|人工神經網絡]]模型，是一种求解单隐层[[前馈神经网络|前馈神经网络]]的学习[[算法|算法]]。

==特點==
传统的[[前馈神经网络|前馈神经网络]]（如BP神经网络）需要人为设置大量的网络训练[[参数|参数]]，此算法卻只需要设定网络的结构，而不需设置其他参数，因此具有简单易用的特点。其输入层到隐藏层的权值是一次随机确定的，算法执行过程中不需要再调整，而隐藏层到输出层的[[權值_(網路)|权值]]只需解一个[[线性方程组|线性方程组]]来确定，因此可以提升计算速度。

==開發==
极限学习机的名稱來自[[新加坡|新加坡]][[南洋理工大學|南洋理工大學]][[黃廣斌|黃廣斌]]教授所建立的模型<ref name="ExtremeLearningMachine"/>。黃教授指出，此算法的泛化性能良好，且其學習速度比運用[[反向传播算法|反向传播算法]]訓練的速度要快上1000倍<ref name="ExtremeLearningMachine">{{cite journal |last1=Huang |first1=Guang-Bin |first2=Qin-Yu |last2=Zhu |first3=Chee-Kheong |last3=Siew |title=Extreme learning machine: theory and applications |journal=Neurocomputing |volume=70 |issue=1 |year=2006 |pages=489–501 |doi=10.1016/j.neucom.2005.12.126<!-- |citeseerx=10.1.1.217.3692-->}}</ref>。

== 算法 ==
极限学习机中最简单的原理如下：

:<math>\mathbf{\hat{Y}} = \mathbf{W}_2 \sigma(\mathbf{W}_1 x)</math>

其中{{math|'''W'''<sub>1</sub>}}是输入向量到隐藏节点层的权重矩阵，{{mvar|σ}}是[[激活函数|激活函数]]，{{math|'''W'''<sub>2</sub>}}是隐藏节点层到输出向量的权重矩阵。算法按下列步骤进行：

# 用随机产生的[[高斯噪声|高斯噪声]]给矩阵{{math|'''W'''<sub>1</sub>}}的每个元素赋值；
# 用[[最小二乘法|最小二乘法]]估计使期望输出{{math|'''Y'''}}与实际输出误差最小的输出权重矩阵{{math|'''W'''<sub>2</sub>}}，数学上能够证明计算隐藏节点层输出矩阵的[[摩尔－彭若斯广义逆|广义逆]] {{math|⋅<sup>+</sup>}} 即可<ref name="ExtremeLearningMachine"/>：
#:<math>\mathbf{W}_2 = \sigma(\mathbf{W}_1 \mathbf{X})^+ \mathbf{Y}</math>

==參見==
* [[機器學習|機器學習]]
* [[前馈神经网络|前馈神经网络]]
* [[人工神經網絡|人工神經網絡]]

== 參考資料 ==
{{reflist}}
[[Category:神經網路|Category:神經網路]]

==外部链接==
* [http://www.ntu.edu.sg/home/egbhuang/elm_codes.html 南洋理工学院极限学习机网站，附源代码、未决难题、ELM会议、教程、参考资料等]
* [https://cran.r-project.org/web/packages/ELMR/ ELM的R程序包]
* {{github|holandajunior/ExtremeLearningMachine|ELM开源程序（Python）}}
* {{github|AntixK/Extreme-Learning-Machine|ELM开源程序（C++）}}
* {{github|wentaozhu/constrained-extreme-learning-machine|ELM开源程序（Matlab）}}