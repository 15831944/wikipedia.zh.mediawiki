'''概率的潜在语义分析'''（'''PLSA）'''，也称为'''概率潜在语义索引'''（'''PLSI'''，尤其是在信息检索领域），是用于分析双模和共现数据的统计方法。 实际上，人们可以根据对某些隐变量的亲和性来推导出观测变量的低维表示，就像PLSA是从[[潜在语义分析|潜在语义分析中]]演化而来。

与源于[[线性代数|线性代数]]并缩小发生表（通常通过[[奇异值分解|奇异值分解]]）的标准潜在语义分析所不同的是，概率潜在语义分析基于从潜类模型导出的混合分解。

== 模型 ==
[[File:Plsi_1.svg|缩略图]]，主题 <math>c</math>是一个[[隐变量|潜变量]]。]]
考虑到以单词和文档的共现 '''<math>(w,d)</math>'''形式进行的观察，PLSA将每次共现的概率建模为条件独立的多项分布的混合：

: <math>P(w,d) = \sum_c P(c) P(d|c) P(w|c) = P(d) \sum_c P(c|d) P(w|c)</math>

其中'c'是单词的主题。值得注意的是，模型的主题数量是一个超参数，必须提前设置而不是从数据中估计。第一个公式是对称式，其中 <math>w</math>和 <math>d</math>都是以类似的方式从[[潜变量|潜变量]] <math>c</math>生成（基于条件概率 <math>P(d|c)</math>和 <math>P(w|c)</math>）；而第二个公式是不对称的 ，对于每个文档 <math>d</math>根据 <math>P(c|d)</math>有条件地从文档中选择潜在类 <math>c</math>，然后根据 <math>P(w|c)</math>从该类生成一个单词。虽然在这个例子中我们使用单词和文档建模，但是任何离散变量的共现也可以用完全相同的方式建模。

因此，模型参数的数量等于 <math>cd + wc</math>，参数数量随文档数量呈线性增长。此外，尽管PLSA是基于文档集的生成模型，但它并不是新文档的生成模型。

模型的参数使用[[最大期望算法|最大期望算法]]（EM算法）学习得到。

== 应用 ==
PLSA可以通过Fisher核函数用于判别设置。<ref>Thomas Hofmann, [https://papers.nips.cc/paper/1654-learning-the-similarity-of-documents-an-information-geometric-approach-to-document-retrieval-and-categorization.pdf ''Learning the Similarity of Documents : an information-geometric approach to document retrieval and categorization''], [[Advances_in_Neural_Information_Processing_Systems|Advances in Neural Information Processing Systems]] 12, pp-914-920, [[MIT_Press|MIT Press]], 2000</ref>

PLSA在[[信息检索|信息检索]]和过滤、[[自然语言处理|自然语言处理]]、文本[[机器学习|机器学习]]及其他相关领域都有应用。

根据报告，概率潜在语义分析中使用的方面模型存在严重的[[过拟合|过拟合]]问题。<ref>{{cite journal|title=Latent Dirichlet Allocation|journal=Journal of Machine Learning Research|year=2003|first=David M.|last=Blei|author2=Andrew Y. Ng |author3=Michael I. Jordan |volume=3|pages=993–1022|id= |url=http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf|doi=10.1162/jmlr.2003.3.4-5.993}}</ref>

== 扩展 ==

* 分层扩展：
** 不对称：MASHA（Multinomial ASymmetric Hierarchical Analysis，多项式非对称分层分析）<ref>Alexei Vinokourov and Mark Girolami, [http://citeseer.ist.psu.edu/rd/30973750,455249,1,0.25,Download/http://citeseer.ist.psu.edu/cache/papers/cs/22961/http:zSzzSzcis.paisley.ac.ukzSzvino-ci0zSzvinokourov_masha.pdf/vinokourov02probabilistic.pdf A Probabilistic Framework for the Hierarchic Organisation and Classification of Document Collections], in ''Information Processing and Management'', 2002</ref>
** 对称：HPLSA（Hierarchical Probabilistic Latent Semantic Analysis，分层概率潜在语义分析）<ref>
Eric Gaussier, Cyril Goutte, Kris Popat and Francine Chen,
[http://www.xrce.xerox.com/Research-Development/Publications/2002-004 A Hierarchical Model for Clustering and Categorising Documents] {{Wayback|url=http://www.xrce.xerox.com/Research-Development/Publications/2002-004 |date=20160304033131 }}, in "Advances in Information Retrieval -- Proceedings of the 24th [[Information_Retrieval_Specialist_Group|BCS-IRSG]] European Colloquium on IR Research (ECIR-02)", 2002
</ref>

* 生成模型：已经开发了以下模型来解决经常被批评的PLSA缺点——它不是新文档的正确生成模型。
** [[潜在狄利克雷分配模型|潜在狄利克雷分配]]（LDA）——在每个文档-主题分布上添加狄利克雷先验
* 高阶数据：尽管在科学文献中很少讨论这一点，但PLSA可以自然地扩展到更高阶数据（三种模式或更高阶），它可以模拟三个或更多变量的共现。在上面的对称公式中，这仅需要为这些附加变量添加条件概率分布就可以实现。这是非负张量因子分解的概率类比。

== 历史 ==
这是[[潜类模型|潜类模型]]的一个特例（参见其中的参考文献），它与[[非负矩阵分解|非负矩阵分解]]有关。<ref>Chris Ding, Tao Li, Wei Peng (2006). "[http://www.aaai.org/Papers/AAAI/2006/AAAI06-055.pdf Nonnegative Matrix Factorization and Probabilistic Latent Semantic Indexing: Equivalence Chi-Square Statistic, and a Hybrid Method. AAAI 2006" ]</ref><ref>Chris Ding, Tao Li, Wei Peng (2008). "[http://www.sciencedirect.com/science/article/pii/S0167947308000145 On the equivalence between Non-negative Matrix Factorization and Probabilistic Latent Semantic Indexing"]</ref>当前的术语是由Thomas Hofmann在1999年创造的。<ref>Thomas Hofmann, [https://arxiv.org/pdf/1301.6705.pdf ''Probabilistic Latent Semantic Indexing''], Proceedings of the Twenty-Second Annual International [[Special_Interest_Group_on_Information_Retrieval|SIGIR]] Conference on Research and Development in [[Information_Retrieval|Information Retrieval]] (SIGIR-99), 1999</ref>

== 参见 ==

* [[向量空間模型|向量空间模型]]

== 参考文献 ==
<references group="" responsive=""></references>

== 外部链接 ==

* [https://web.archive.org/web/20050120213347/http://www.cs.brown.edu/people/th/papers/Hofmann-UAI99.pdf 概率潜在语义分析（PDF）]
* [http://www.semanticquery.com/archive/semanticsearchart/researchpLSA.html C#编写的PLSA的DEMO]
[[Category:语言模型|Category:语言模型]]
[[Category:统计自然语言处理|Category:统计自然语言处理]]
[[Category:有未审阅翻译的页面|Category:有未审阅翻译的页面]]