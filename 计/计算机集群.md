{{NoteTA
|G1 = IT
}}
[[File:MEGWARE.CLIC.jpg|thumb]]的技术人员在一个大型[[Linux|Linux]]集群上工作]]
[[File:Sun_Microsystems_Solaris_computer_cluster.jpg|thumb]]

'''计算机集群'''（{{lang-en|computer cluster}}）是一组松散或紧密连接在一起工作的[[電子計算機|计算机]]。由于这些计算机协同工作，在许多方面它们可以被视为单个系统。与[[网格计算|网格计算机]]不同，计算机集群将每个{{le|节点 (计算机科学)|Node (computer science)|节点}}设置为执行相同的任务，由软件控制和调度。

集群的组件通常通过快速[[局域网|局域网]]相互连接，每个'''节点'''（用作服务器的计算机）运行自己的[[操作系统|操作系统]]实例。在大多数情况下，所有节点使用相同的硬件<ref>{{cite web|url=https://stackoverflow.com/questions/9723040/what-is-the-difference-between-cloud-grid-and-cluster|title=Cluster vs grid computing|website=[[Stack_Overflow|Stack Overflow]]}}</ref>和相同的操作系统，尽管在某些设置中（例如使用{{le|OSCAR|Open Source Cluster Application Resources}}），可以在每台计算机或不同的硬件上使用不同的操作系统。<ref name=pcauthority>{{cite web|url=http://www.pcauthority.com.au/Feature/306972,weekend-project-build-your-own-supercomputer.aspx|title=Weekend Project: Build your own supercomputer|date=29 June 2012|first=Darien|last=Graham-Smith|website=PC & Tech Authority|access-date=2 June 2017}}</ref>

部署集群通常是为了提高单台计算机的性能和可用性，而集群也通常比速度或可用性相当的单台计算机的成本效益要高。<ref>{{cite web |url=http://www.cc.gatech.edu/~bader/papers/ijhpca.html|title=Cluster Computing: Applications |last=Bader |first=David|authorlink=David A. Bader|date=May 2001|website=|publisher=[[Georgia_Institute_of_Technology_College_of_Computing|Georgia Tech College of Computing]]|first2=Robert|last2=Pennington|accessdate=2017-02-28}}</ref>

计算机集群的出现是许多计算趋势汇聚的结果，这些趋势包括低成本微处理器、高速网络以及用于高性能[[分布式计算|分布式计算]]软件的广泛使用。集群使用和部署广泛，从小型企业集群到世界上最快[[超级电脑|超级电脑]]（如[[红杉_(超级电脑)|IBM的Sequoia]]）。<ref>{{cite web|url=https://www.telegraph.co.uk/technology/9338651/Nuclear-weapons-supercomputer-reclaims-world-speed-record-for-US.html|title=Nuclear weapons supercomputer reclaims world speed record for US|publisher=The Telegraph|date=18 Jun 2012|accessdate=18 Jun 2012}}</ref>  在集群出现之前，人们采用具有[[Triple_modular_redundancy|模块冗余]]的单元[[故障容許度|容错]][[大型计算机|主机]]；但是，集群的前期成本较低，网络结构速度提高，这助推了人们采用集群这种方式。与高可靠性的大型机集群相比，扩展成本更低，但也增加了错误处理的复杂性，因为在集群中错误模式对于运行的程序是不透明的。<ref>{{cite book |last1=Gray |first1=Jim |last2=Rueter |first2=Andreas |title=Transaction processing : concepts and techniques |date=1993 |publisher=Morgan Kaufmann Publishers |isbn=1558601902}}</ref>

==基本概念==
[[File:Beowulf.jpg|thumb]]。]]
为了通过组合低成本的商用现成计算机，来获得更大的计算能力和更好的可靠性，人们研究提出了各种架构和配置。

计算机集群方法通常通过快速[[局域网|局域网]]连接许多现成的计算节点（例如用作服务器的个人计算机）。<ref name=nbis>{{cite conference|title=Network-Based Information Systems: First International Conference, NBIS 2007|ISBN=3-540-74572-6|page=375}}</ref> 计算节点的活动由“集群中间件”协调，集群中间件是一个位于节点之上的软件层，让用户可以将集群视为一个整体的内聚计算单元（例如通过[[单系统映像|单系统映像]]概念）。<ref name=nbis />

计算机集群依赖于一种集中管理方法，该方法把节点用作协调的共享服务器。它不同于其他方法（比如[[對等網路|对等计算]]或[[网格计算|网格计算]]），后者也使用许多节点，但具有更多的[[分布式计算|分布式特性]]。<ref name=nbis />

计算机集群可能是一个简单的两节点系统，只连接两台个人电脑，也可能是一台速度非常快的[[超级计算机|超级计算机]]。构建集群的基本方法是[[贝奥武夫机群|贝奥武夫机群]]，它可以使用少量个人计算机构建，以产生与传统[[超级计算机|高性能计算]]相比经济划算的替代方案。一个展示概念可行性的早期项目是133节点的[[Stone_Soupercomputer|Stone Soupercomputer]]。<ref name="sciam">{{Cite news |title= The Do-It-Yourself Supercomputer |work= [[科学美国人|Scientific American]] |author= William W. Hargrove, Forrest M. Hoffman and [[Thomas_Sterling_(computing)|Thomas Sterling]] |volume= 265 |number= 2 |pages= 72–79 |date= August 16, 2001 |url= http://www.sciam.com/article.cfm?id=the-do-it-yourself-superc |accessdate= October 18, 2011 }}</ref> 开发人员使用[[Linux|Linux]]、{{le|并行虚拟机|Parallel Virtual Machine}}工具包和[[訊息傳遞介面|訊息傳遞介面]]库以相对较低的成本实现高性能。<ref name="extreme">{{Cite news |title= Cluster Computing: Linux Taken to the Extreme |first1= William W.|last1=Hargrove|first2=Forrest M.|last2=Hoffman |work= Linux Magazine |year= 1999 |url= http://climate.ornl.gov/~forrest/linux-magazine-1999/ |accessdate= October 18, 2011}}</ref>

尽管一个集群可能仅由几台通过简单网络连接的个人计算机组成，但集群架构也可用于实现非常高的性能水平。[[TOP500|TOP500]]组织每半年公布的500台最快[[超级计算机|超级计算机]]的名单通常包括许多集群，例如，2011年世界上最快的机器是“[[京_(超级计算机)|京]]”，它有{{le|分布存储器|distributed memory}}和集群架构。<ref>{{cite conference|first=Mitsuo|last=Yokokawa |display-authors=etal |title=The K computer: Japanese next-generation supercomputer development project|conference=International Symposium on Low Power Electronics and Design (ISLPED)|date=1–3 August 2011|pages=371–372|url=http://ieeexplore.ieee.org/document/5993668/|doi=10.1109/ISLPED.2011.5993668}}</ref>

== 历史 ==
{{See also|超级计算机}}
[[File:SPEC-1_VAX_05.jpg|缩略图]]集群 11/780, 拍摄于约1977年]]
Greg Pfister指出，集群最初不是由特定的供应商发明的，而是由无法在一台计算机上完成所有工作或需要备份的客户发明的。 <ref>{{cite book|last=Pfister|first=Gregory|title=In Search of Clusters|edition=2nd|publisher=Prentice Hall PTR|location=Upper Saddle River, NJ|year=1998|page=36|isbn=0-13-899709-8}}</ref> 他估计计算机集群发明于20世纪60年代。 作为并行工作的一种方式，集群计算的正式工程基础可以说是由[[IBM|IBM]]的[[吉恩·阿姆達爾|吉恩·阿姆達爾]]发明的，因为他在1967年出版了被认为是关于并行处理的开创性论文：[[阿姆达尔定律|阿姆达尔定律]]。

早期计算机集群的历史或多或少直接与早期网络的历史有关，因为网络发展的主要动机之一是连接计算资源，创建真正的计算机集群。

第一个被设计成集群的生产系统是20世纪60年代中期的Burroughs {{le|B5700}}，它允许多达四台计算机（每个计算机都有一个或两个处理器）紧密连接到一个公共磁盘存储系统，以平衡工作负载。与标准的多处理器系统不同，每台计算机都可以在不中断整体运行的情况下重新启动。

第一个商业松散耦合的集群产品是{{le|Datapoint}}公司的“附加资源计算机”（Attached Resource Computer，ARC）系统，该系统于1977年开发，使用ARCNET作为集群接口。直到[[迪吉多|迪吉多电脑公司]]在1984年为[[VAX/VMS|VAX/VMS]]操作系统（现在称为OpenVMS）发布了{{le|VAXcluster|VAX集群}}产品，集群才真正开始。ARC和VAX集群产品不仅支持并行计算，还支持共享[[文件系统|文件系统]]和[[外部设备|外部设备]]。其目的是提供并行处理的优势，同时保持数据的可靠性和唯一性。另外两个值得注意的早期商业集群是{{le|Tandem Computers|''Tandem Himalayan''}}（大约1994年出现的高可用性产品）和''IBM S/390 Parallel Sysplex''（也在大约1994年出现，主要用于商业用途）。

同时，当商业网络使用计算机集群在计算机外部的并行性时，超级计算机开始在计算机内部中使用它们。继[[CDC_6600|CDC 6600]]在1964年取得成功之后，{{le|Cray 1}}也于1976年成功发布，并通过[[并行向量处理机|向量处理]]引入了内部并行性。<ref name="Hill412">{{cite book|title=Readings in computer architecture|first1=Mark Donald|last1=Hill|first2=Norman Paul|last2=Jouppi|first3=Gurindar|last3=Sohi|year=1999|ISBN=978-1-55860-539-8|pages=41–48}}</ref> 虽然早期的超级计算机不使用集群而是使用了[[共享内存|共享内存]]，但一些速度最快的超级计算机（如[[京_(超级计算机)|京]]）最终依赖于集群架构。

==集群的属性==
[[File:Balanceamento_de_carga_(NAT).jpg|thumb]]
可以根据不同目的配置计算机集群，从一般用途的业务需求（如Web服务支持），到计算密集型的科学计算。在这两种情况下，集群都可以使用[[high-availability_cluster|高可用性]]方法。请注意，下面描述的属性并不是排他的，“计算机集群”也可以使用高可用性方法等等。

“[[负载均衡|负载均衡]]”集群是集群节点共享计算工作负载，以提供更好的总体性能的配置。例如，Web服务器集群可以将不同的查询分配给不同的节点，因此总体响应时间将得到优化。<ref name=Sloan>{{cite book|title=High Performance Linux Clusters|first=Joseph D.|last=Sloan|year=2004|ISBN=0-596-00570-9}}</ref> 然而，负载平衡的方法可能在不同的应用程序之间有很大的不同，例如，用于科学计算的高性能集群的平衡负载算法与Web服务器集群不同，Web服务器集群可能只是使用一种简单的[[循環制|循环方法]]，将每个新请求分配到不同节点。<ref name=Sloan />

计算机集群用于计算密集型目的，而不是处理[[I/O|面向IO]]的操作（如Web服务或数据库）。<ref name=VECPAR >{{cite book|title=High Performance Computing for Computational Science - VECPAR 2004|first1=Michel|last1=Daydé|first2=Jack|last2=Dongarra|year=2005|ISBN=3-540-25424-2|pages=120–121}}</ref> 例如，计算机集群可能支持车祸或天气的[[计算机模拟|计算模拟]]。非常紧密耦合的计算机集群被设计用于可能接近“[[超级计算机|超级计算]]”的工作。

“高可用性集群”提高了集群方法的可用性。它们通过拥有冗余[[节点_(电信网络)|节点]]来运行，当系统组件出现故障时，这些节点将用于提供服务。高可用性集群实现试图使用集群组件的冗余来消除[[单点故障|单点故障]]。许多操作系统都有高可用性集群的商业实现。[[Linux-HA|Linux-HA]]项目是[[Linux|Linux]]操作系统常用的一个[[自由软件|自由软件]]HA包。

==优点==
<!-- This used to be a list. Work has been done since, but it's still incomplete. -->
集群的设计主要考虑性能，但实际使用中还涉及许多其他因素，包括容错（''能够容许系统继续使用故障节点''）能力、[[可扩展性|可扩展性]]、高性能、不需要频繁运行维护程序、资源整合（如[[RAID|RAID]]）和集中管理。集群的优点包括在发生灾难时启用数据恢复、提供并行数据处理和高计算能力。<ref>{{cite web|url=http://www-03.ibm.com/systems/clusters/benefits.html|title=IBM Cluster System : Benefits|publisher=[[IBM|IBM]]|accessdate=8 September 2014|archive-url=https://web.archive.org/web/20160429022854/http://www-03.ibm.com/systems/clusters/benefits.html|archive-date=29 April 2016|dead-url=yes|df=}}</ref><ref>{{cite web|url=https://technet.microsoft.com/en-us/library/cc778629(v=ws.10).aspx|title=Evaluating the Benefits of Clustering|date=28 March 2003|publisher=[[微软|Microsoft]]|accessdate=8 September 2014|archive-url=https://web.archive.org/web/20160422092651/https://technet.microsoft.com/en-us/library/cc778629%28v%3Dws.10%29.aspx|archive-date=22 April 2016|dead-url=yes|df=}}</ref>

在可伸缩性方面，集群提供了水平添加节点的能力。这意味着可以向集群中添加更多的计算机，以提高其性能、冗余和容错。与在集群中扩展单个节点相比，添加节点是一个既节省成本，又可以使集群获得更高的性能的解决方案。计算机集群的这一大特性允许大量性能较低的计算机执行较大的计算负载。

向集群添加新节点时，可靠性也会增加，这是因为进行维护的时候不需要停下整个集群，只需停下单个节点维护，集群的其余节点承担该节点的负载即可。

如果集群包含大量的计算机，那么可以使用[[分布式文件系统|分布式文件系统]]和[[RAID|RAID]]，这两种方法可以大大提高集群的可靠性和速度。

==设计与配置==
[[File:beowulf.png|thumb]]
设计集群的问题之一是各个节点之间的耦合程度。例如，单个计算机作业可能需要节点之间的频繁通信：这意味着集群共享一个专用网络，位置密集，可能有同类节点。另一个极端是计算机作业使用一个或几个节点，并且需要很少或没有节点间通信，接近[[网格计算|网格计算]]。

在[[贝奥武夫机群|贝奥武夫机群]]中，应用程序从不会看到计算节点（也叫“从属计算机”），只与“主计算机”交互，而“主计算机”是处理从属计算机的调度和管理的特定计算机。<ref name=VECPAR /> 在典型的实现中，主计算机具有两个网络接口，一个用于为从属设备与专用贝奥武夫网络通信，另一个用于组织的通用网络。<ref name=VECPAR /> 从属计算机通常有同一操作系统、本地内存和磁盘空间的它们自己的版本。但是，专用从属网络还可以有大型共享文件服务器，该服务器存储全局持久数据，从属设备可以根据需要访问这些数据。<ref name=VECPAR />

一个特殊用途的144节点[[DEGIMA_(computer_cluster)|DEGIMA集群]]被调整为使用多步行并行树码运行天体物理N体仿真，而不是通用的科学计算。<ref name=Hamada>{{cite journal|first=Tsuyoshi|last=Hamada |display-authors=etal |year=2009|title=A novel multiple-walk parallel algorithm for the Barnes–Hut treecode on GPUs – towards cost effective, high performance N-body simulation|journal=Computer Science - Research and Development|volume=24|pp=21–31|doi=10.1007/s00450-009-0089-1}}</ref>

由于每一代[[電子遊戲機|游戏机]]的计算能力不断增强，一种新的用途出现了，它们被重新用于[[High-performance_computing|高性能计算]]（HPC）集群。游戏机集群的例子有[[PlayStation_3_cluster|索尼PlayStation集群]]和[[微软|微软]][[Xbox_(遊戲機)|Xbox]]集群。另一个消费类游戏产品的例子是[[Nvidia_Tesla_Personal_Supercomputer|Nvidia Tesla个人超级计算机]]工作站，它使用多个图形加速处理器芯片。除了游戏机，也可以使用高端显卡。使用显卡进行网格计算比使用CPU更经济，尽管不太精确。但是，当使用双精度值时，它们变得像CPU一样精确，并且成本更低。<ref name=pcauthority />

计算机集群历来在使用相同[[操作系统|操作系统]]的独立物理[[電子計算機|计算机]]上运行。随着[[虛擬化|虛擬化]]技术的出现，集群节点可以在具有不同操作系统的独立物理计算机上运行，这些操作系统上面绘制了一个虚拟层，使之看起来相似。<ref name=linuxjournal>{{cite web|url=http://www.linuxjournal.com/article/8812|title=Xen Virtualization and Linux Clustering, Part 1|date=12 Jan 2006|website=Linux Journal|first=Ryan|last=Mauer|access-date=2 Jun 2017}}</ref> 当进行维护时，集群还可以在各种配置上进行虚拟化。一个示例实现是[[Xen|Xen]]作为[[Linux-HA|Linux-HA]]的虚拟化管理器。<ref name="linuxjournal" />

==数据共享与通信==

===数据共享===
[[File:Nec-cluster.jpg|thumb]]的[[Nehalem微架構|Nehalem集群]]]]
随着计算机集群在20世纪80年代的出现，[[超级计算机|超级计算机]]也应运而生。早期的超级计算机依赖于[[共享内存|共享内存]]，这是当时这三类计算机的区别之一。迄今为止，集群通常不使用物理共享内存，而许多超级计算机体系结构也放弃了这一点。

不过，在现代计算机集群中，[[集群文件系统|集群文件系统]]的使用是必不可少的。例如{{le|IBM通用并行文件系统|IBM General Parallel File System}}、Microsoft的{{le|集群共享卷|Cluster Shared Volumes}}或{{le|Oracle集群文件系统|Oracle Cluster File System}}。

===消息传递与通信===
用于集群节点间通信的两种广泛使用的方法是MPI（[[訊息傳遞介面|訊息傳遞介面]]）和PVM（{{le|并行虚拟机|Parallel Virtual Machine}}）。<ref name=Gehrke>{{cite book|title=Distributed services with OpenAFS: for enterprise and education|first1=Franco|last1=Milicchio|first2=Wolfgang Alexander|last2=Gehrke|year=2007|ISBN=9783540366348|pages=339–341|url=https://books.google.ca/books?id=_HtHG2Ca5AEC}}</ref>

早在1989年MPI出现之前，PVM就在[[橡树岭国家实验室|橡树岭国家实验室]]问世了。PVM必须直接安装在每个集群节点上，并提供一组软件库，将节点描绘成一个“并行虚拟机”。PVM为消息传递、任务和资源管理以及故障通知提供了一个运行时环境。PVM可以由用C、C++或Fortran等语言编写的用户程序使用。<ref name="Gehrke" /><ref name="Prabhu" />

20世纪90年代初，在40个组织的讨论中产生了MPI。最初的努力得到了[[國防高等研究計劃署|ARPA]]和[[国家科学基金会|国家科学基金会]]的支持。MPI的设计没有重新开始，而是利用了当时商业系统中可用的各种特性。MPI规范催生了具体的实现。MPI实现通常使用[[TCP/IP协议族|TCP/IP]]和套接字连接。<ref name=Gehrke /> MPI现在是一种广泛使用的通信模型，它使并行程序能够用[[C语言|C]]、[[Fortran|Fortran]]、[[Python|Python]]等语言编写。<ref name=Prabhu >{{cite book|url=https://books.google.ca/books?id=evcgB7Qlix4C|title=Grid and Cluster Computing|last=Prabhu|first=C.S.R.|year=2008|isbn=8120334280|pages=109–112}}</ref> 因此，与提供具体实现的PVM不同，MPI是已经在诸如[[MPICH|MPICH]]和[[Open_MPI|Open MPI]]的系统中实现的规范。<ref name="Prabhu" /><ref name=Gropp>{{Cite journal
|last1=Gropp |first1=William |last2=Lusk |first2=Ewing |last3=Skjellum |first3=Anthony
|year=1996|citeseerx = 10.1.1.102.9485
|title=A High-Performance, Portable Implementation of the MPI Message Passing Interface
|journal=Parallel Computing |ref=harv}}</ref>

==集群管理==
[[File:Cubieboard_HADOOP_cluster.JPG|thumb]]上使用[[Apache_Hadoop|Apache Hadoop]]，低成本、低能耗的[[Cubieboard|Cubieboard]]微型集群]]
使用计算机集群服务器的挑战之一是管理它的成本，如果集群有N个节点，有时可能高达管理N个独立机器的成本。<ref name=patter641 >{{cite book|title=Computer Organization and Design|first1=David A.|last1=Patterson|first2=John L.|last2=Hennessy|year=2011|ISBN=0-12-374750-3|pages=641–642}}</ref> 在某些情况下，这为管理成本较低的[[共享内存|共享内存架构]]提供了一个优势。<ref name=patter641 /> 由于便于管理，这也使得[[虛擬機器|虚拟机]]非常流行。<ref name=patter641 />

===任务调度===
当大型多用户集群需要访问大量数据时，[[调度_(计算机)|任务调度]]就成为一个挑战。在具有复杂应用环境的异构CPU-GPU集群中，每项作业的性能取决于底层集群的特性。因此，将任务映射到CPU内核和GPU设备有巨大的挑战。<ref name=Shira /> 这是一个正在进行的研究领域；结合和扩展[[MapReduce|MapReduce]]和[[Apache_Hadoop|Hadoop]]的算法已经被提出和研究。<ref name=Shira >{{cite conference|author=K. Shirahata |display-authors=etal |title=Hybrid Map Task Scheduling for GPU-Based Heterogeneous Clusters|conference=Cloud Computing Technology and Science (CloudCom) |date=30 Nov – 3 Dec 2010|pages=733–740|ISBN=978-1-4244-9405-7|url=http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5708524|doi=10.1109/CloudCom.2010.55}}</ref>

===节点故障管理===
当集群中的一个节点出现故障时，可以使用诸如“[[Fencing_(computing)|fencing]]”（隔离）之类的策略来保持系统的其余部分可操作。<ref name=ARob>{{cite web|first=Alan|last=Robertson|title=Resource fencing using STONITH|website=IBM Linux Research Center|year=2010|url=ftp://ftp.telecom.uff.br/pub/linux/HA/ResourceFencing_Stonith.pdf}}</ref><ref name=suncl >{{cite book|title=Sun Cluster environment: Sun Cluster 2.2|first1=Enrique|last1=Vargas|first2=Joseph|last2=Bianco|first3=David|last3=Deeths|year=2001|ISBN=9780130418708|page=58|url=https://books.google.ca/books?id=oRjWAZS5iZMC|publisher=Prentice Hall Professional}}</ref> Fencing是在节点出现故障时隔离节点或保护共享资源的过程。有两类隔离方法；一类禁用节点本身，另一类禁用对资源（如共享磁盘）的访问。<ref name=ARob />

[[STONITH|STONITH]]方法（Shoot The Other Node In The Head）是说禁用或关闭可疑的节点。例如，'''电源fencing'''使用电源控制器来关闭无法操作的节点。<ref name=ARob />

'''资源fencing'''方法不允许在不关闭节点电源的情况下访问资源。这可能包括通过[[SCSI3|SCSI3]]持久保留fencing，禁用[[光纤通道|光纤通道]]端口的光纤通道fencing，或禁用[[网络块设备|GNBD]]服务器访问的GNBD fencing。

==软件开发和管理==

===并行编程===
负载平衡集群（如Web服务器）使用集群架构来支持大量用户，通常每个用户请求都被路由到一个特定的节点，实现无需多节点协作的[[任务并行|任务并行]]，因为系统的主要目标是让用户快速访问共享数据。然而，为少数用户执行复杂计算的"计算机集群"需要利用集群的并行处理能力，在多个节点之间划分"相同的计算"。<ref name=Blum />

程序的{{le|自动并行化|Automatic parallelization}}仍然是一个技术挑战，但是{{le|并行编程模型|parallel programming model}}可以通过在不同的处理器上同时执行程序的不同部分来实现更高{{le|并行度|degree of parallelism|程度的并行性}}。<ref name=Blum >{{cite book|title=Computer Science: The Hardware, Software and Heart of It|first1=Alfred V.|last1=Aho|first2=Edward K.|last2=Blum|year=2011|ISBN=1-4614-1167-X|pages=156–166|url=https://books.google.com/books?id=S7QU9RRLYIYC}}</ref><ref>{{cite book|title=Parallel Programming: For Multicore and Cluster Systems|first1=Thomas|last1=Rauber|first2=Gudula|last2=Rünger|year=2010|ISBN=3-642-04817-X|pages=94–95|url=https://books.google.com/books?id=wWogxOmA3wMC}}</ref>

===调试和监控===
在集群上开发和调试并行程序需要并行语言原语以及合适的工具，例如'''高性能调试论坛'''（HPDF）所讨论的那些工具，HPD规范就是这样产生的。<ref name=Prabhu /><ref name=iosp>{{cite journal|title=A Debugging Standard for High-performance computing|first1=Joan M.|last1=Francioni|author-link2=Cherri M. Pancake|first2=Cherri M.|last2=Pancake|journal=Scientific Programming|volume=8|issue=2|date=April 2000|url=http://dl.acm.org/citation.cfm?id=1239906|doi=10.1155/2000/971291|publisher=IOS Press|issn=1058-9244|pages=95–108|location=[[阿姆斯特丹|Amsterdam]], [[荷兰|Netherlands]]}}</ref>
像[[Rogue_Wave_Software|TotalView]]这样的工具是为了在使用[[訊息傳遞介面|MPI]]或[[Parallel_Virtual_Machine|PVM]]进行消息传递的计算机集群上调试并行实现而开发的。

[[加利福尼亞大學柏克萊分校|Berkeley]] NOW（Network of Workstations）系统收集集群数据并将其存储在数据库中，而在印度开发的PARMON系统允许对大型集群进行可视化观察和管理。<ref name=Prabhu />

当一个节点在长时间的多节点计算中失败时，可以使用{{le|应用程序检查点|Application checkpointing}}来恢复给定的系统状态。<ref name=sloot >{{cite conference|title=Computational Science-- ICCS 2003: International Conference|editor-first=Peter|editor-last=Sloot|year=2003|ISBN=3-540-40195-4|pages=291–292}}</ref> 这在大型集群中是必不可少的，因为随着节点数量的增加，在繁重的计算负载下节点失败的可能性也会增加。检查点可以将系统恢复到稳定状态，这样处理就可以在不重新计算结果的情况下继续进行。<ref name=sloot />

==一些实现==
GNU/Linux世界提供了各种集群软件；对于应用程序集群，有[[distcc|distcc]]和[[MPICH|MPICH]]。[[Linux虚拟服务器|Linux Virtual Server]], [[Linux-HA|Linux-HA]]等基于导向器的集群，允许传入的服务请求分布在多个集群节点上。[[MOSIX|MOSIX]]、[[LinuxPMI|LinuxPMI]]、[[Kerrighed|Kerrighed]]、[[OpenSSI|OpenSSI]]都是集成到[[内核|内核]]中的成熟集群，它们可在同类节点之间自动进行进程迁移。[[OpenSSI|OpenSSI]]、[[openMosix|openMosix]]和[[Kerrighed|Kerrighed]]是[[单系统映像|单系统映像]]实现。

基于[[Windows_Server|Windows Server]]平台的[[Microsoft_Windows|Microsoft Windows]]计算机群集Server 2003为高性能计算提供了诸如Job Scheduler、MSMPI库和管理工具。

[[gLite|gLite]]是{{le|E-sciencE网格计划|Enabling Grids for E-sciencE}}（EGEE）创建的一组中间件技术。

[[Slurm工作调度工具|slurm]]还用于调度和管理一些最大的超级计算机集群（参见top500列表）。

==其他方法==
尽管大多数计算机集群都是永久性的，但是人们已经尝试用{{le|快闪计算|flash mob computing}}来为特定的计算构建短期集群。不过，更大规模的{{le|志愿计算|volunteer computing}}系统（如基于[[BOINC|BOINC]]的系统）的追随者更多。

== 参见 ==
{| cellspacing="5" cellpadding="5" border="0" width="60%"
|-
|valign="top" width="30%"|
基本概念
:* [[集群文件系统|集群文件系统]]
:* {{le|心跳专用网络|Heartbeat private network}}
:* {{le|高可用性集群|High-availability cluster}}
:* [[单系统映像|单系统映像]]
:* [[对称多处理|对称多处理]]
分布式计算
:* [[分布式计算|分布式计算]]
:* [[分散式檔案系統|分散式檔案系統]]
:* [[分布式操作系统|分布式操作系统]]
:* [[分布式共享存储处理机|分布式共享存储处理机]]
|valign="top" width="30%"|
具体系统
:* [[DEGIMA_(computer_cluster)|DEGIMA (computer cluster)]]
:* [[京_(超级计算机)|京 (超级计算机)]]
:* {{le|微软集群服务器|Microsoft Cluster Server}}
:* [[红帽集群套件|红帽集群套件]]
:* {{le|Rocks集群发行版|Rocks Cluster Distribution}}
:* {{le|Solaris集群|Solaris Cluster}}
:* {{le|Veritas集群服务器|Veritas Cluster Server}}

计算工厂
:* {{le|编译工厂|Compile farm}}
:* [[著色農場|著色農場]]
:* [[服务器农场|服务器农场]]
|}

== 参考资料 ==
{{Reflist|30em}}

== 延伸阅读 ==

* {{cite arxiv|first=Mark|last=Baker |display-authors=etal |title=Cluster Computing White Paper|arxiv=cs/0004014|date=11 Jan 2001}}
* {{cite book|first1=Evan|last1=Marcus|first2=Hal|last2=Stern|title=Blueprints for High Availability: Designing Resilient Distributed Systems|publisher=John Wiley & Sons|ISBN=0-471-35601-8}}
* {{cite book|first1=Greg|last1=Pfister|title=In Search of Clusters|publisher=Prentice Hall|ISBN=0-13-899709-8}}
* {{cite book|editor-first=Rajkumar|editor-last=Buyya|title=High Performance Cluster Computing: Architectures and Systems|volume=1|ISBN=0-13-013784-7|publisher=Prentice Hall|location=NJ, USA|year=1999}}
* {{cite book|editor-first=Rajkumar|editor-last=Buyya|title=High Performance Cluster Computing: Architectures and Systems|volume=2|ISBN=0-13-013785-5|publisher=Prentice Hall|location=NJ, USA|year=1999}}

== 外部链接 ==
{{Commons}}
* [https://www.ieeetcsc.org/ IEEE Technical Committee on Scalable Computing (TCSC)]
* [http://publib.boulder.ibm.com/infocenter/clresctr/vxrx/index.jsp?topic=%2Fcom.ibm.cluster.rsct.doc%2Frsctbooks.html Reliable Scalable Cluster Technology, IBM]
* [https://www.ibm.com/developerworks/wikis/display/tivoli/Tivoli+System+Automation Tivoli System Automation Wiki]
* [https://static.googleusercontent.com/media/research.google.com/en/us/pubs/archive/43438.pdf Large-scale cluster management at Google with Borg], April 2015, by Abhishek Verma, Luis Pedrosa, Madhukar Korupolu, David Oppenheimer, Eric Tune and John Wilkes

{{并行计算}}

[[Category:叢集計算|]]
[[Category:并行计算|Category:并行计算]]
[[Category:并发计算|Category:并发计算]]
[[Category:超級電腦|Category:超級電腦]]
[[Category:局域网|Category:局域网]]
[[Category:電腦的類別|Category:電腦的類別]]