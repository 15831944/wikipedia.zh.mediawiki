{{Refimprove|time=2017-05-23T07:42:41+00:00}}
{{专家}}
{{NoteTA
|G1=IT
|1=zh-hans:过拟合; zh-hant:過適;
|2=zh-hans:拟合; zh-hant:調適;
}}

[[Image:Overfitting.svg|thumb]]

在[[統計學|統計學]]中，'''過適'''（{{lang-en|'''overfitting'''}}，或稱'''過度擬合'''）[[現象|現象]]是指在調適一個[[統計模型|統計模型]]時，使用過多[[參數|參數]]。

對比於可取得的資料總量來說，一個荒謬的模型只要足夠複雜，是可以完美地適應資料。過適一般可以視為違反[[奥卡姆剃刀|奥卡姆剃刀]]原則。

當可選擇的參數的自由度超過資料所包含資訊內容時，這會導致最後（調適後）模型使用任意的參數，這會減少或破壞模型一般化的能力更甚於適應資料。過適的可能性不只取決於參數個數和資料，也跟模型架構與資料的一致性有關。此外對比於資料中預期的雜訊或錯誤數量，跟模型錯誤的數量也有關。

過適現象的觀念對[[機器學習|機器學習]]也是很重要的。通常一個學習[[演算法|演算法]]是藉由訓練範例來訓練的。亦即預期結果的範例是可知的。而學習者則被認為須達到可以預測出其它範例的正確的結果，因此，應適用於一般化的情況而非只是訓練時所使用的現有資料（根據它的[[歸納偏向|歸納偏向]]）。然而，學習者卻會去適應訓練資料中太特化但又隨機的特徵，特別是在當學習過程太久或範例太少時。在過適的過程中，當預測訓練範例結果的表現增加時，應用在未知資料的表現則變更差。

在統計和機器學習中，為了避免過適現象，須要使用額外的技巧（如[[交叉驗證|交叉驗證]]、{{le|提早停止|early stopping}}、{{link-en|貝斯信息量準則|Bayesian information criterion}}、[[赤池信息量準則|赤池信息量準則]]或{{le|模型比较|model comparison}}），以指出何時會有更多訓練而沒有導致更好的一般化。[[人工神經網路|人工神經網路]]的過適過程亦被認知為過度訓練（{{lang-en|overtraining}}）。在treatmeant learning中，使用最小最佳支援值（{{lang-en|minimum best support value}}）來避免過適。

相對於過適是指，使用過多參數，以致太適應資料而非一般情況，另一種常見的現象是使用太少參數，以致於不適應資料，這則稱為'''乏適'''（{{lang-en|underfitting}}，或稱：擬合不足）現象。

== 參考文獻 ==
{{Reflist}}
* Tetko, I.V.; Livingstone, D.J.; Luik, A.I. Neural network studies. 1. Comparison of Overfitting and Overtraining, [http://www.vcclab.org/articles/tetko.html#overtraining  J. Chem. Inf. Comput. Sci., 1995, 35, 826-833]

== 外部連結 ==
* http://www.cs.sunysb.edu/~skiena/jaialai/excerpts/node16.html
* [http://www.vcclab.org/articles/tetko.html#overtraining 過度訓練]{{en}}

== 參見 ==
* {{tsl|en|Data dredging|数据疏通}}

[[Category:回歸分析|Category:回歸分析]]
[[Category:數據挖掘|Category:數據挖掘]]
[[Category:機器學習|Category:機器學習]]